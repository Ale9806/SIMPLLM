{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHORS: Alejandro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc5f02-9b1e-4d4f-992b-082fa056154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2520cd-a77c-48af-800e-bde935e2dbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch ;print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc649d14-6d6f-4535-b46f-5a55d618b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 23 05:54:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P0    26W /  70W |      0MiB / 15360MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7088e55-0451-49a5-8ae6-1f2bb4817f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from   torch.utils.data      import Dataset, DataLoader\n",
    "from   torch_geometric.data  import Data\n",
    "from   torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim:int, hidden_dim:int, output_dim:int, layers:int, dropout:float=0.3, return_embedding=False):\n",
    "        \"\"\"\n",
    "            A stack of GraphSAGE Module \n",
    "            input_dim        <int>:   Input dimension\n",
    "            hidden_dim       <int>:   Hidden dimension\n",
    "            output_dim       <int>:   Output dimension\n",
    "            layers           <int>:   Number of layers\n",
    "            dropout          <float>: Dropout rate\n",
    "            return_embedding <bool>:  Whether to return the return_embeddingedding of the input graph\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        graphSage_conv               = pyg.nn.SAGEConv\n",
    "        self.dropout                 = dropout\n",
    "        self.layers                  = layers\n",
    "        self.return_embedding        = return_embedding\n",
    "\n",
    "        ### Initalize the layers ###\n",
    "        self.convs                   = nn.ModuleList()                      # ModuleList to hold the layers\n",
    "        for l in range(self.layers):\n",
    "            if l == 0:\n",
    "                ### First layer  maps from input_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                ### All other layers map from hidden_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing processing MLP\n",
    "        self.post_mp = nn.Sequential(\n",
    "                                     nn.Linear(hidden_dim, hidden_dim), \n",
    "                                     nn.Dropout(self.dropout),\n",
    "                                     nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return final layer of return_embeddingeddings if specified\n",
    "        if self.return_embedding:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "    \n",
    "\n",
    "\n",
    "class LinkPredictorMLP(nn.Module):\n",
    "    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int):     Number of input features.\n",
    "            hidden_channels (int): Number of hidden features.\n",
    "            out_channels (int):    Number of output features.\n",
    "            n_layers (int):        Number of MLP layers.\n",
    "            dropout (float):       Dropout probability.\n",
    "            \"\"\"\n",
    "        super(LinkPredictorMLP, self).__init__()\n",
    "        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n",
    "        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n",
    "        self.non_linearity         = F.relu              # non-linearity\n",
    "        \n",
    "        for i in range(n_layers - 1):                                 \n",
    "            if i == 0:\n",
    "                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n",
    "            else:\n",
    "                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n",
    "\n",
    "        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for mlp_layer in self.mlp_layers:\n",
    "            mlp_layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j                                                     # element-wise multiplication\n",
    "        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n",
    "            x = mlp_layer(x)                                              # apply linear transformation\n",
    "            x = self.non_linearity(x)                                     # Apply non linear activation function\n",
    "            x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n",
    "        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n",
    "        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n",
    "        return x\n",
    "    \n",
    "### We will use This function to save our best model during trainnig ###\n",
    "def save_torch_model(model,epoch,PATH:str,optimizer):\n",
    "    print(f\"Saving Model in Path {PATH}\")\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer':optimizer,      \n",
    "                }, PATH)\n",
    "    \n",
    "    \n",
    "def train(model, link_predictor, dataset, optimizer,device:str=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    :param model: Torch Graph model used for updating node embeddings based on message passing \n",
    "        (If None, no embbeding is performed) \n",
    "    :param link_predictor: Torch model used for predicting whether edge exists or not\n",
    "    :param emb: (N, d) Initial node embeddings for all N nodes in graph\n",
    "    :param edge_index: (2, E) Edge index for all edges in the graph\n",
    "\n",
    "    :param optimizer: Torch Optimizer to update model parameters\n",
    "    :return: Average supervision loss over all positive (and correspondingly sampled negative) edges\n",
    "    \"\"\"\n",
    "    if model != None:\n",
    "        model.train()\n",
    "    link_predictor.train()\n",
    "    train_losses = []\n",
    "    for x, edge_index in tqdm(dataset):                       # Get X and Index from Dataste\n",
    "        optimizer.zero_grad()                                 # Reset Gradients\n",
    "        edge_index     = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "        x              = x.squeeze(dim=1)                     # Reshape Feature matrix (|N|,D)\n",
    "        x , edge_index = x.to(device) , edge_index.to(device) # Move data to devices\n",
    "        \n",
    "        \n",
    "        ### Step 1: Get Embeddings:\n",
    "        # Run message passing on the inital node embeddings to get updated embeddings\n",
    "        \n",
    "        ### This model has the option of only running link predictor without graphsage, for that case the node embedding\n",
    "        ### is equal to the original embedding (X)\n",
    "        if model !=  None:\n",
    "            node_emb   = model(data.x_dict, data.edge_index_dict) # Embed Bert Embeddigns with graphsage (N, d) \n",
    "            \n",
    "        else:\n",
    "            node_emb = x                     # Else (None) use Bert Embedddings\n",
    "        # Predict the class probabilities on the batch of positive edges using link_predictor\n",
    "        #print(node_emb[edge_index[0]].shape)\n",
    "        edge_index = data['compounds', 'treats', 'disease'].edge_index   \n",
    "        pred       = link_predictor(node_emb[\"compounds\"][edge_index[0]], node_emb[\"disease\"][edge_index[0]])   # (B, )\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "        # Backpropagate and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    return sum(train_losses) / len(train_losses)\n",
    "\n",
    "\n",
    "def evaluate(model, predictor,dataset,device=\"cpu\",threshold=0.5,ppi_:int=0.9,verbose:bool=False,best_accuracy=0,show_extra_metrics:bool=False):\n",
    "    if model != None:\n",
    "        model.eval()\n",
    "    possitive_acc  = 0 \n",
    "    negative_acc   = 0\n",
    "    batches        = 0\n",
    "    if show_extra_metrics:\n",
    "        yhat_total     = []\n",
    "        y_total        = []\n",
    "        \n",
    "    for x, edge_index in dataset:                              # Get X and Index from Dataste\n",
    "\n",
    "        edge_index      = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "        number_of_edges =  edge_index.shape[1]                 # Retrive number of edges \n",
    "        permutations    =  torch.randperm(number_of_edges)     # Create Permutations for edge index\n",
    "        edge_index      = edge_index[:,permutations]           # Run permutation\n",
    "        limit           = int(ppi_*number_of_edges)            # get limit  (based on ppis to embed)\n",
    "        ppi_index_embed = edge_index[:,0:limit]                # PPI to embed with GraphSage \n",
    "        ppi_index_infer = edge_index[:,limit:]                 # PPI to make inference\n",
    "        \n",
    "        x                    = x.squeeze(dim=1)                          # Reshape Feature matrix (|N|,D)\n",
    "        x ,ppi_index_embed   = x.to(device) , ppi_index_embed.to(device) # Move data to devices\n",
    "        if model !=  None:\n",
    "            node_emb             = model(x,ppi_index_embed)              # Get all node embeddings\n",
    "        else:\n",
    "            node_emb = x                                                 # Else (None) use Bert Embedddings\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\" {limit} Positive Protein Interactions were used to Embed a graph with {number_of_edges} ppi's\")\n",
    "        \n",
    "        del ppi_index_embed \n",
    "        with torch.no_grad():\n",
    "            ### Positive PPI ###\n",
    "            positive_pairs_embeddings = node_emb[ppi_index_infer[0]].to(device), node_emb[ppi_index_infer[1]].to(device)\n",
    "            predictions               = predictor(positive_pairs_embeddings[0], positive_pairs_embeddings[1]) \n",
    "            y                         = torch.ones_like(input=predictions)\n",
    "            predictions,y             = predictions.cpu(),y.cpu()\n",
    "            possitive_acc            += accuracy_score(predictions > threshold  ,y)\n",
    "            if show_extra_metrics:\n",
    "                yhat_total.extend(predictions.tolist())\n",
    "                y_total.extend(y.tolist())\n",
    "                \n",
    "            else:\n",
    "                del y, predictions , positive_pairs_embeddings,ppi_index_infer\n",
    "\n",
    "            ### Negative PPI ##\n",
    "            edge_index  =  edge_index.to(device)\n",
    "            neg_edge    = negative_sampling(edge_index       = edge_index,        # Possitve PPI's\n",
    "                                         num_nodes        = x.shape[0],           # Total number of nodes in graph\n",
    "                                         num_neg_samples  = edge_index.shape[1],  # Same Number of edges as in positive example\n",
    "                                         method           = 'dense',              # Method for edge generation\n",
    "                                         force_undirected = True)                 # Our graph is undirected\n",
    "\n",
    "            negative_pairs_embeddings = node_emb[neg_edge[0]].to(device), node_emb[neg_edge[1]].to(device)\n",
    "            predictions               = predictor(negative_pairs_embeddings[0], negative_pairs_embeddings[1])   \n",
    "            y                         = torch.zeros_like(input=predictions)\n",
    "            predictions,y             = predictions.cpu(),y.cpu()\n",
    "            negative_acc             += accuracy_score(predictions > threshold,y)\n",
    "            if show_extra_metrics:\n",
    "                yhat_total.extend(predictions.tolist())\n",
    "                y_total.extend(y.tolist())\n",
    "                \n",
    "            else:\n",
    "                del y,  predictions  ,negative_pairs_embeddings \n",
    "            batches +=1\n",
    "\n",
    "    negative_acc  = negative_acc/batches\n",
    "    possitive_acc = possitive_acc/batches\n",
    "    total_acc     = 0.5*possitive_acc  + 0.5*negative_acc\n",
    "    if show_extra_metrics == False:\n",
    "        print(f\"Sensitivity (poss_acc):{possitive_acc:.4f} Specificity (negative_acc):{negative_acc:.4f} accuracy:{total_acc:.4f}\")\n",
    "    \n",
    "    elif show_extra_metrics == True:\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2,figsize=(10,2))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve( y_total, yhat_total)\n",
    "        \n",
    "        sens      =  tpr\n",
    "        spec      =  1 - fpr\n",
    "        j         = sens + spec -1\n",
    "        opt_index = np.where(j == np.max(j))[0][0]\n",
    "        op_point  = thresholds[opt_index]\n",
    "        \n",
    "        print(f\"Youdens  index: {op_point:.4f} Sensitivity: {round(sens[opt_index],4)} Specificity: {round(spec[opt_index],4)}\")\n",
    "       \n",
    "        ax[0].set_title(\"ROC Curve\")\n",
    "        ax[1].set_title(\"Confussion Matrix\")\n",
    "        if model == None:\n",
    "            ax[0].plot(fpr,tpr,label=\"MLP\") \n",
    "        else:\n",
    "            ax[0].plot(fpr,tpr,label=\"GraphSage+MLP\") \n",
    "        ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "        ax[0].set_ylabel('True Positive Rate')\n",
    "        ax[0].set_xlabel('False Positive Rate')\n",
    "        ax[0].legend()\n",
    "       \n",
    "    \n",
    "        cfm = metrics.confusion_matrix(y_total, np.array(yhat_total)> op_point)\n",
    "        \n",
    "        cmn = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis] # Normalise\n",
    "        disp = ConfusionMatrixDisplay(cmn)\n",
    "        disp.plot(ax=ax[1])\n",
    "        \n",
    "        plt.show()\n",
    "     \n",
    "    return total_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8addf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os \n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9ecb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"data\",\"graph_obj\")\n",
    "GRAPH     = T.ToUndirected()(torch.load(DATA_PATH, map_location=\"cpu\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390dbfd1-74bb-4a88-ace9-148f95da9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 48185])\n",
      "HeteroData(\n",
      "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
      "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
      "  \u001b[1m(Compound, treats, Disease)\u001b[0m={ edge_index=[2, 48185] },\n",
      "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "data['Compound'].x  =  GRAPH[\"Compound\"][\"x\"]\n",
    "data['Disease'].x   = GRAPH[\"Disease\"][\"x\"]\n",
    "ctd                 = GRAPH[(\"Compound\", \"Compound treats the disease\", \"Disease\")][\"edge_index\"].to_sparse()\n",
    "data['Compound', 'treats', 'Disease'].edge_index = ctd\n",
    "target_label                                     = data['Compound', 'treats', 'Disease'].edge_index\n",
    "#data['Compound', 'treats', 'Disease'].edge_label =  torch.ones(target_label.shape[1],)\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(target_label.shape)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b87637c5-c139-442b-89a3-7f7da55443c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31034 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43986 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:20475 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4733 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16728 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:819 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1077 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mRandomLinkSplit(\n\u001b[1;32m      2\u001b[0m     num_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      3\u001b[0m     num_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     rev_edge_types\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m train_data, val_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrain_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mval_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/transforms/random_link_split.py:191\u001b[0m, in \u001b[0;36mRandomLinkSplit.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient number of edges for training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Create data splits:\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_disjoint\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_undirected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrev_edge_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(val_store, train_edges, is_undirected, rev_edge_type)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(test_store, train_val_edges, is_undirected,\n\u001b[1;32m    195\u001b[0m             rev_edge_type)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/transforms/random_link_split.py:271\u001b[0m, in \u001b[0;36mRandomLinkSplit._split\u001b[0;34m(self, store, index, is_undirected, rev_edge_type)\u001b[0m\n\u001b[1;32m    268\u001b[0m             value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([value, value], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    269\u001b[0m         store[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 271\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_undirected:\n\u001b[1;32m    273\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, edge_index\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m0\u001b[39m])], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31034 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43986 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at aten/src/ATen/RegisterFunctionalization_0.cpp:20475 [kernel]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\nZeroTensor: registered at aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4733 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:15232 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16728 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:819 [kernel]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1077 [kernel]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.01,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=3.0,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=('Compound', 'treats', 'Disease'),\n",
    "    rev_edge_types=('Compound', 'rev_treats', 'Disease'), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "\n",
    "print(f\"Train Data:\\n{train_data}\")\n",
    "print(f\"Validation Data:\\n{val_data}\")\n",
    "print(f\"Test Data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd606e44-c2bd-4d6e-8a81-5be9d88a0b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Compound'].x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88bc9a53-2f6a-40af-aa0f-f47aad6af794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Loaded to cpu\n"
     ]
    }
   ],
   "source": [
    "epochs        = 500\n",
    "hidden_dim    = 524      # 256 \n",
    "dropout       = 0.7\n",
    "num_layers    = 3\n",
    "learning_rate = 1e-4\n",
    "node_emb_dim  = 768\n",
    "device        = \"cpu\"\n",
    "\n",
    "HomoGNN         = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embedding=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\n",
    "HeteroGNN       = to_hetero(HomoGNN   , data.metadata(), aggr='mean')\n",
    "link_predictor  = LinkPredictorMLP(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device) # the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\n",
    "#optimizer      = torch.optim.AdamW(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate, weight_decay=1e-4)\n",
    "optimizer       = torch.optim.Adam(list(HeteroGNN.parameters()) + list(link_predictor.parameters() ), lr=learning_rate)\n",
    "\n",
    "#print(HeteroGNN )\n",
    "#print(link_predictor)\n",
    "print(f\"Models Loaded to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76256b4e-a709-4972-bf43-7a75b3afecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:65: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:69: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  src = src.to_sparse_csr()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_emb   \u001b[38;5;241m=\u001b[39m \u001b[43mHeteroGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:281\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.3:12\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m edge_index__Disease__rev_treats__Compound \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m edge_index__Compound__rev_treats__Disease \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m);  edge_index_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m convs_0__Disease1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompound__treats__Disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__Compound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx__Disease\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index__Compound__treats__Disease\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mDisease__rev_treats__Compound((x__Disease, x__Compound), edge_index__Disease__rev_treats__Compound)\n\u001b[1;32m     14\u001b[0m convs_0__Disease2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mCompound__rev_treats__Disease((x__Compound, x__Disease), edge_index__Compound__rev_treats__Disease);  x__Compound \u001b[38;5;241m=\u001b[39m x__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:435\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m         edge_index, msg_aggr_kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 435\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_aggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    437\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:150\u001b[0m, in \u001b[0;36mSAGEConv.message_and_aggregate\u001b[0;34m(self, adj_t, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adj_t, SparseTensor):\n\u001b[1;32m    149\u001b[0m     adj_t \u001b[38;5;241m=\u001b[39m adj_t\u001b[38;5;241m.\u001b[39mset_value(\u001b[38;5;28;01mNone\u001b[39;00m, layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:84\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(src, other, reduce)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Use the default code path with custom reduction (works on CPU):\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csr \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Simulate `mean` reduction by dividing by degree:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)"
     ]
    }
   ],
   "source": [
    "node_emb   = HeteroGNN(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac59d155-c08e-4616-b593-dfa7813ff12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Compound', 'treats', 'Disease'].edge_index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2abdbd8-a2d4-4936-8ae3-d26b54095781",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding needs to remove . \n",
    "del GRAPH ['inhibits cell growth (esp. cancers)']\n",
    "del GRAPH['rev_inhibits cell growth (esp. cancers)']\n",
    "del GRAPH ['binding, ligand (esp. receptors)']\n",
    "del GRAPH['rev_binding, ligand (esp. receptors)']\n",
    "\n",
    "\n",
    "# saved as none \n",
    "del GRAPH['increases expression/production']\n",
    "del GRAPH['rev_increases expression/production']\n",
    "del GRAPH[(\"Compound\", 'increases expression/production', \"Gene\")]\n",
    "del GRAPH[(\"Compound\", 'decreases expression/production', \"Gene\")]\n",
    "del GRAPH[(\"Compound\", 'affects expression/production (neutral)', \"Gene\")]\n",
    "del GRAPH[(\"Compound\", 'metabolism, pharmacokinetics', \"Gene\")]\n",
    "del GRAPH[(\"Compound\", 'transport, channels', \"Gene\")]\n",
    "del GRAPH[(\"Compound\", 'biomarkers (of_disease_progression)', \"Disease\")]\n",
    "del GRAPH[(\"Compound\", 'alleviates, reduces', \"Disease\")]\n",
    "del GRAPH[(\"Compound\", 'prevents, suppresses', \"Disease\")]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fd78d8d-7bcf-405b-8db5-a7bb9b037959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "HeteroData(\n",
      "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
      "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
      "  \u001b[1m(Compound, treats, Disease)\u001b[0m={\n",
      "    edge_index=[2, 26985],\n",
      "    edge_label=[46256],\n",
      "    edge_label_index=[2, 46256]\n",
      "  },\n",
      "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] },\n",
      "  \u001b[1m(Compound, rev_treats, Disease)\u001b[0m={}\n",
      ")\n",
      "Validation Data:\n",
      "HeteroData(\n",
      "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
      "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
      "  \u001b[1m(Compound, treats, Disease)\u001b[0m={\n",
      "    edge_index=[2, 38549],\n",
      "    edge_label=[19272],\n",
      "    edge_label_index=[2, 19272]\n",
      "  },\n",
      "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] },\n",
      "  \u001b[1m(Compound, rev_treats, Disease)\u001b[0m={}\n",
      ")\n",
      "Test Data:\n",
      "HeteroData(\n",
      "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
      "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
      "  \u001b[1m(Compound, treats, Disease)\u001b[0m={\n",
      "    edge_index=[2, 43367],\n",
      "    edge_label=[19272],\n",
      "    edge_label_index=[2, 19272]\n",
      "  },\n",
      "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] },\n",
      "  \u001b[1m(Compound, rev_treats, Disease)\u001b[0m={}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=3.0,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=('Compound', 'treats', 'Disease'),\n",
    "    rev_edge_types=('Compound', 'rev_treats', 'Disease'), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "\n",
    "print(f\"Train Data:\\n{train_data}\")\n",
    "print(f\"Validation Data:\\n{val_data}\")\n",
    "print(f\"Test Data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76ebefc2-d4ac-438a-a070-6019372c390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_index = train_data['Compound', 'treats', 'Disease'].edge_label_index\n",
    "edge_label       = train_data['Compound', 'treats', 'Disease'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc73a6a-92ee-417b-b218-90410dfd9216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a36c57e6-7d18-4293-b554-cfd58bd147c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m edge_label_index \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39medge_label_index\n\u001b[1;32m      4\u001b[0m edge_label       \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39medge_label\n\u001b[0;32m----> 7\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mLinkNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_sampling_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_label_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompound\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDisease\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_label_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/loader/link_neighbor_loader.py:206\u001b[0m, in \u001b[0;36mLinkNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, edge_label_index, edge_label, edge_label_time, replace, directed, disjoint, temporal_strategy, neg_sampling, neg_sampling_ratio, time_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived conflicting \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_label_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_label_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39medge_label_time\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot set\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtime_attr\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot set\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbor_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     neighbor_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemporal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemporal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    219\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    220\u001b[0m     link_sampler\u001b[38;5;241m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    230\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:79\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, replace, directed, disjoint, temporal_strategy, time_attr, is_sorted, share_memory)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_edge_type \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Convert the graph data into CSC format for sampling:\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m colptr_dict, row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperm \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero_csc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_time_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_dict \u001b[38;5;241m=\u001b[39m remap_keys(row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolptr_dict \u001b[38;5;241m=\u001b[39m remap_keys(colptr_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:109\u001b[0m, in \u001b[0;36mto_hetero_csc\u001b[0;34m(data, device, share_memory, is_sorted, node_time_dict)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge_type, store \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_items():\n\u001b[1;32m    108\u001b[0m     src_node_time \u001b[38;5;241m=\u001b[39m (node_time_dict \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(edge_type[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 109\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mto_csc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_node_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     colptr_dict[edge_type], row_dict[edge_type], perm_dict[edge_type] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m colptr_dict, row_dict, perm_dict\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:69\u001b[0m, in \u001b[0;36mto_csc\u001b[0;34m(data, device, share_memory, is_sorted, src_node_time)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     colptr, row, _ \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39madj_t\u001b[38;5;241m.\u001b[39mcsr()\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sorted:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data['Compound', 'treats', 'Disease'].edge_label_index\n",
    "edge_label       = train_data['Compound', 'treats', 'Disease'].edge_label\n",
    "\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=(('Compound', 'treats', 'Disease'), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "512912c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:50: UserWarning: Using '{self.__class__.__name__}' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print(GRAPH)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGRAPH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m   \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Sample 15 neighbors for each node and each edge type for 2 iterations:\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Use a batch size of 128 for sampling training nodes of type \"paper\":\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompound\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/loader/neighbor_loader.py:198\u001b[0m, in \u001b[0;36mNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, directed, disjoint, temporal_strategy, time_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived conflicting \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m arguments: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbor_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     neighbor_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemporal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemporal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    211\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    212\u001b[0m     node_sampler\u001b[38;5;241m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    219\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:79\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, replace, directed, disjoint, temporal_strategy, time_attr, is_sorted, share_memory)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_edge_type \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Convert the graph data into CSC format for sampling:\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m colptr_dict, row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperm \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero_csc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_time_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_dict \u001b[38;5;241m=\u001b[39m remap_keys(row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolptr_dict \u001b[38;5;241m=\u001b[39m remap_keys(colptr_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:109\u001b[0m, in \u001b[0;36mto_hetero_csc\u001b[0;34m(data, device, share_memory, is_sorted, node_time_dict)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge_type, store \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_items():\n\u001b[1;32m    108\u001b[0m     src_node_time \u001b[38;5;241m=\u001b[39m (node_time_dict \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(edge_type[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 109\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mto_csc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_node_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     colptr_dict[edge_type], row_dict[edge_type], perm_dict[edge_type] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m colptr_dict, row_dict, perm_dict\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:69\u001b[0m, in \u001b[0;36mto_csc\u001b[0;34m(data, device, share_memory, is_sorted, src_node_time)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     colptr, row, _ \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39madj_t\u001b[38;5;241m.\u001b[39mcsr()\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sorted:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "#print(GRAPH)\n",
    "train_loader = NeighborLoader(\n",
    "    GRAPH,\n",
    "   \n",
    "    num_neighbors=[15] * 2,   # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "    batch_size=128,           # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "    input_nodes=('Compound'),\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "356cbdbc-f561-49c9-a915-1b456c7ed56f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:79\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subgraph_loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersistent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/loader/neighbor_loader.py:198\u001b[0m, in \u001b[0;36mNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, directed, disjoint, temporal_strategy, time_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived conflicting \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m arguments: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbor_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     neighbor_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemporal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemporal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    211\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    212\u001b[0m     node_sampler\u001b[38;5;241m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    219\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:79\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, replace, directed, disjoint, temporal_strategy, time_attr, is_sorted, share_memory)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_edge_type \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Convert the graph data into CSC format for sampling:\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m colptr_dict, row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperm \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero_csc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_time_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_dict \u001b[38;5;241m=\u001b[39m remap_keys(row_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolptr_dict \u001b[38;5;241m=\u001b[39m remap_keys(colptr_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_rel_type)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:109\u001b[0m, in \u001b[0;36mto_hetero_csc\u001b[0;34m(data, device, share_memory, is_sorted, node_time_dict)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge_type, store \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_items():\n\u001b[1;32m    108\u001b[0m     src_node_time \u001b[38;5;241m=\u001b[39m (node_time_dict \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(edge_type[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 109\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mto_csc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_node_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     colptr_dict[edge_type], row_dict[edge_type], perm_dict[edge_type] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m colptr_dict, row_dict, perm_dict\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:69\u001b[0m, in \u001b[0;36mto_csc\u001b[0;34m(data, device, share_memory, is_sorted, src_node_time)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     colptr, row, _ \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39madj_t\u001b[38;5;241m.\u001b[39mcsr()\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sorted:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/data/storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "subgraph_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=None,\n",
    "    num_neighbors=[-1],\n",
    "    batch_size=4096,\n",
    "    num_workers=12,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe2f5432-cfbc-4242-9bd9-9b998b24bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:156: UserWarning: There exist node types ({'Compound'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m device        \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m HomoGNN         \u001b[38;5;241m=\u001b[39m GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# the graph neural network that takes all the node embeddings as inputs to message pass and agregate\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m HeteroGNN       \u001b[38;5;241m=\u001b[39m \u001b[43mto_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHomoGNN\u001b[49m\u001b[43m   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m link_predictor  \u001b[38;5;241m=\u001b[39m LinkPredictorMLP(hidden_dim, hidden_dim, \u001b[38;5;241m1\u001b[39m, num_layers , dropout)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#optimizer      = torch.optim.AdamW(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate, weight_decay=1e-4)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:120\u001b[0m, in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mwhich node representations are learned for each node type in\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m        transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m transformer \u001b[38;5;241m=\u001b[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/fx.py:157\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_global_pooling_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, op, node\u001b[38;5;241m.\u001b[39mtarget):\n\u001b[1;32m    156\u001b[0m         op \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_global_pooling_module\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Remove all unused nodes in the computation graph, i.e., all nodes\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# which have been replaced by node type-wise or edge type-wise variants\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# but which are still present in the computation graph.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# We do this by iterating over the computation graph in reversed order,\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# and try to remove every node. This does only succeed in case there\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# are no users of that node left in the computation graph.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes)):\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:321\u001b[0m, in \u001b[0;36mToHeteroTransformer.call_function\u001b[0;34m(self, node, target, name)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minserting_after(node)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_edge_level(node))]:\n\u001b[0;32m--> 321\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_args_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    323\u001b[0m                                  args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    324\u001b[0m                                  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minserting_after(out)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:414\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs\u001b[0;34m(self, node, key)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 414\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    415\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:414\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 414\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_recurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    415\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/to_hetero_transformer.py:404\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs.<locals>._recurse\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    400\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_by_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    401\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_by_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey2str(key[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: _recurse(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "843be519-7281-46ef-b1f2-3bf122e98d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH.x_dict\n",
    "#GRAPH.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fc5118b-0414-49c1-b3c7-ec4e94cb975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ModuleDict(\n",
       "    (Compound__treats__Disease): SAGEConv(768, 524, aggr=mean)\n",
       "    (Disease__rev_treats__Compound): SAGEConv(768, 524, aggr=mean)\n",
       "    (Compound__rev_treats__Disease): SAGEConv(768, 524, aggr=mean)\n",
       "  )\n",
       "  (1-2): 2 x ModuleDict(\n",
       "    (Compound__treats__Disease): SAGEConv(524, 524, aggr=mean)\n",
       "    (Disease__rev_treats__Compound): SAGEConv(524, 524, aggr=mean)\n",
       "    (Compound__rev_treats__Disease): SAGEConv(524, 524, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HeteroGNN.convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5dc794b4-f3be-451b-9ed8-369cab4931c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:65: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:69: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  src = src.to_sparse_csr()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_emb   \u001b[38;5;241m=\u001b[39m \u001b[43mHeteroGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:281\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.3:12\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m edge_index__Disease__rev_treats__Compound \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m edge_index__Compound__rev_treats__Disease \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m);  edge_index_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m convs_0__Disease1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompound__treats__Disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__Compound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx__Disease\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index__Compound__treats__Disease\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mDisease__rev_treats__Compound((x__Disease, x__Compound), edge_index__Disease__rev_treats__Compound)\n\u001b[1;32m     14\u001b[0m convs_0__Disease2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mCompound__rev_treats__Disease((x__Compound, x__Disease), edge_index__Compound__rev_treats__Disease);  x__Compound \u001b[38;5;241m=\u001b[39m x__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:435\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m         edge_index, msg_aggr_kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 435\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_aggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    437\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:150\u001b[0m, in \u001b[0;36mSAGEConv.message_and_aggregate\u001b[0;34m(self, adj_t, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adj_t, SparseTensor):\n\u001b[1;32m    149\u001b[0m     adj_t \u001b[38;5;241m=\u001b[39m adj_t\u001b[38;5;241m.\u001b[39mset_value(\u001b[38;5;28;01mNone\u001b[39;00m, layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:84\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(src, other, reduce)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Use the default code path with custom reduction (works on CPU):\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csr \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Simulate `mean` reduction by dividing by degree:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "077fdb47-6cba-4a38-9477-b8ce095eaf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict['Compound','treats','Disease'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aff3fc26-6756-487b-b92d-5cae8a27af7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abc1c24a-7294-43be-b772-aae933b326f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Initialize lazy modules.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     node_emb   \u001b[38;5;241m=\u001b[39m \u001b[43mHeteroGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:281\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.3:14\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     12\u001b[0m convs_0__Disease1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mCompound__treats__Disease((x__Compound, x__Disease), edge_index__Compound__treats__Disease)\n\u001b[1;32m     13\u001b[0m convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mDisease__rev_treats__Compound((x__Disease, x__Compound), edge_index__Disease__rev_treats__Compound)\n\u001b[0;32m---> 14\u001b[0m convs_0__Disease2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompound__rev_treats__Disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__Compound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx__Disease\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index__Compound__rev_treats__Disease\u001b[49m\u001b[43m)\u001b[49m;  x__Compound \u001b[38;5;241m=\u001b[39m x__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     15\u001b[0m convs_0__Disease \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(convs_0__Disease1, convs_0__Disease2);  convs_0__Disease1 \u001b[38;5;241m=\u001b[39m convs_0__Disease2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m relu__Compound \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(convs_0__Compound, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m);  convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:422\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m         edge_index, size, kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 422\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Run \"fused\" message and aggregation (if applicable).\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse(edge_index) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplain:\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:235\u001b[0m, in \u001b[0;36mMessagePassing._check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    232\u001b[0m         the_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m size[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m the_size\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`MessagePassing.propagate` only supports integer tensors of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape `[2, num_messages]`, `torch_sparse.SparseTensor` or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    238\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`torch.sparse.Tensor` for argument `edge_index`.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: `MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    node_emb   = HeteroGNN(val_data.x_dict, val_data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3356121-f81c-491d-9692-45c4084ade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb   = HeteroGNN(GRAPH.x_dict, GRAPH.edge_index_dict)\n",
    "edge_index = GRAPH['compounds', 'treats', 'disease'].edge_index \n",
    "pos_pred    = link_predictor(node_emb[\"compounds\"][edge_index[0]], node_emb[\"disease\"][edge_index[0]])   # (B, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d837ed-ca88-423d-ba39-8f123f5a8d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simp",
   "language": "python",
   "name": "simp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
