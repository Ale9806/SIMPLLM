{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnQGl_D4786T"
   },
   "source": [
    "DRKG\n",
    "\n",
    "Adapted from: https://github.com/gnn4dr/DRKG/blob/master/drkg_with_dgl/loading_drkg_in_dgl.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PV4N5XSIKfTa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from   torch.utils.data      import Dataset, DataLoader\n",
    "from   torch_geometric.data  import Data\n",
    "from   torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SIMP_LLM.dataloader_mappings import load_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_as_list(file_path):\n",
    "    data = []\n",
    "    set_ = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[3] == 'Atc' or row[3] == \"Tax\":\n",
    "                continue\n",
    "            else:\n",
    "                data.append((row[1],row[2],row[3]))\n",
    "    return data\n",
    "triplets = load_csv_as_list('triplets.csv')\n",
    "#triplets =  list(set(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2\n"
     ]
    }
   ],
   "source": [
    "triplets =[('Compound', 'Compound_treats_the_disease', 'Disease')]\n",
    "data = load_graph(triplets )\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = torch.load(\"data2/mapping_dict\")\n",
    "#dictionaries[\"Compound\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim:int, hidden_dim:int, output_dim:int, layers:int, dropout:float=0.3, return_embedding=False):\n",
    "        \"\"\"\n",
    "            A stack of GraphSAGE Module \n",
    "            input_dim        <int>:   Input dimension\n",
    "            hidden_dim       <int>:   Hidden dimension\n",
    "            output_dim       <int>:   Output dimension\n",
    "            layers           <int>:   Number of layers\n",
    "            dropout          <float>: Dropout rate\n",
    "            return_embedding <bool>:  Whether to return the return_embeddingedding of the input graph\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        graphSage_conv               = pyg.nn.SAGEConv\n",
    "        self.dropout                 = dropout\n",
    "        self.layers                  = layers\n",
    "        self.return_embedding        = return_embedding\n",
    "\n",
    "        ### Initalize the layers ###\n",
    "        self.convs                   = nn.ModuleList()                      # ModuleList to hold the layers\n",
    "        for l in range(self.layers):\n",
    "            if l == 0:\n",
    "                ### First layer  maps from input_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                ### All other layers map from hidden_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing processing MLP\n",
    "        self.post_mp = nn.Sequential(\n",
    "                                     nn.Linear(hidden_dim, hidden_dim), \n",
    "                                     nn.Dropout(self.dropout),\n",
    "                                     nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return final layer of return_embeddingeddings if specified\n",
    "        if self.return_embedding:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    #def loss(self, pred, label):\n",
    "    #    return F.nll_loss(pred, label)\n",
    "    \n",
    "\n",
    "\n",
    "class LinkPredictorMLP(nn.Module):\n",
    "    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int):     Number of input features.\n",
    "            hidden_channels (int): Number of hidden features.\n",
    "            out_channels (int):    Number of output features.\n",
    "            n_layers (int):        Number of MLP layers.\n",
    "            dropout (float):       Dropout probability.\n",
    "            \"\"\"\n",
    "        super(LinkPredictorMLP, self).__init__()\n",
    "        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n",
    "        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n",
    "        self.non_linearity         = F.relu              # non-linearity\n",
    "        \n",
    "        for i in range(n_layers - 1):                                 \n",
    "            if i == 0:\n",
    "                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n",
    "            else:\n",
    "                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n",
    "\n",
    "        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for mlp_layer in self.mlp_layers:\n",
    "            mlp_layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j                                                     # element-wise multiplication\n",
    "        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n",
    "            x = mlp_layer(x)                                              # apply linear transformation\n",
    "            x = self.non_linearity(x)                                     # Apply non linear activation function\n",
    "            #x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n",
    "            #x = F.dropout(x, p=self.dropout_probabilty)      # Apply dropout\n",
    "        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n",
    "        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n",
    "        return x\n",
    "    \n",
    "### We will use This function to save our best model during trainnig ###\n",
    "def save_torch_model(model,epoch,PATH:str,optimizer):\n",
    "    print(f\"Saving Model in Path {PATH}\")\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer':optimizer,      \n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
       "  \u001b[1mDisease\u001b[0m={ x=[4098, 768] },\n",
       "  \u001b[1m(Compound, Compound_treats_the_disease, Disease)\u001b[0m={ edge_index=[2, 48554] },\n",
       "  \u001b[1m(Disease, rev_Compound_treats_the_disease, Compound)\u001b[0m={ edge_index=[2, 48554] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(768, 524, aggr=mean)\n",
      "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(768, 524, aggr=mean)\n",
      "    )\n",
      "    (1-2): 2 x ModuleDict(\n",
      "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(524, 524, aggr=mean)\n",
      "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(524, 524, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (post_mp): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (Compound): Dropout(p=0.7, inplace=False)\n",
      "      (Disease): Dropout(p=0.7, inplace=False)\n",
      "    )\n",
      "    (2): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__Compound = x_dict.get('Compound', None)\n",
      "    x__Disease = x_dict.get('Disease', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__Compound__Compound_treats_the_disease__Disease = edge_index_dict.get(('Compound', 'Compound_treats_the_disease', 'Disease'), None)\n",
      "    edge_index__Disease__rev_Compound_treats_the_disease__Compound = edge_index_dict.get(('Disease', 'rev_Compound_treats_the_disease', 'Compound'), None);  edge_index_dict = None\n",
      "    convs_0__Disease = getattr(self.convs, \"0\").Compound__Compound_treats_the_disease__Disease((x__Compound, x__Disease), edge_index__Compound__Compound_treats_the_disease__Disease)\n",
      "    convs_0__Compound = getattr(self.convs, \"0\").Disease__rev_Compound_treats_the_disease__Compound((x__Disease, x__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  x__Disease = x__Compound = None\n",
      "    relu__Compound = torch.nn.functional.relu(convs_0__Compound, inplace = False);  convs_0__Compound = None\n",
      "    relu__Disease = torch.nn.functional.relu(convs_0__Disease, inplace = False);  convs_0__Disease = None\n",
      "    dropout__Compound = torch.nn.functional.dropout(relu__Compound, p = 0.7, training = True, inplace = False);  relu__Compound = None\n",
      "    dropout__Disease = torch.nn.functional.dropout(relu__Disease, p = 0.7, training = True, inplace = False);  relu__Disease = None\n",
      "    convs_1__Disease = getattr(self.convs, \"1\").Compound__Compound_treats_the_disease__Disease((dropout__Compound, dropout__Disease), edge_index__Compound__Compound_treats_the_disease__Disease)\n",
      "    convs_1__Compound = getattr(self.convs, \"1\").Disease__rev_Compound_treats_the_disease__Compound((dropout__Disease, dropout__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  dropout__Disease = dropout__Compound = None\n",
      "    relu_1__Compound = torch.nn.functional.relu(convs_1__Compound, inplace = False);  convs_1__Compound = None\n",
      "    relu_1__Disease = torch.nn.functional.relu(convs_1__Disease, inplace = False);  convs_1__Disease = None\n",
      "    dropout_1__Compound = torch.nn.functional.dropout(relu_1__Compound, p = 0.7, training = True, inplace = False);  relu_1__Compound = None\n",
      "    dropout_1__Disease = torch.nn.functional.dropout(relu_1__Disease, p = 0.7, training = True, inplace = False);  relu_1__Disease = None\n",
      "    convs_2__Disease = getattr(self.convs, \"2\").Compound__Compound_treats_the_disease__Disease((dropout_1__Compound, dropout_1__Disease), edge_index__Compound__Compound_treats_the_disease__Disease);  edge_index__Compound__Compound_treats_the_disease__Disease = None\n",
      "    convs_2__Compound = getattr(self.convs, \"2\").Disease__rev_Compound_treats_the_disease__Compound((dropout_1__Disease, dropout_1__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  dropout_1__Disease = dropout_1__Compound = edge_index__Disease__rev_Compound_treats_the_disease__Compound = None\n",
      "    relu_2__Compound = torch.nn.functional.relu(convs_2__Compound, inplace = False);  convs_2__Compound = None\n",
      "    relu_2__Disease = torch.nn.functional.relu(convs_2__Disease, inplace = False);  convs_2__Disease = None\n",
      "    dropout_2__Compound = torch.nn.functional.dropout(relu_2__Compound, p = 0.7, training = True, inplace = False);  relu_2__Compound = None\n",
      "    dropout_2__Disease = torch.nn.functional.dropout(relu_2__Disease, p = 0.7, training = True, inplace = False);  relu_2__Disease = None\n",
      "    post_mp_0__Compound = getattr(self.post_mp, \"0\").Compound(dropout_2__Compound);  dropout_2__Compound = None\n",
      "    post_mp_0__Disease = getattr(self.post_mp, \"0\").Disease(dropout_2__Disease);  dropout_2__Disease = None\n",
      "    post_mp_1__Compound = getattr(self.post_mp, \"1\").Compound(post_mp_0__Compound);  post_mp_0__Compound = None\n",
      "    post_mp_1__Disease = getattr(self.post_mp, \"1\").Disease(post_mp_0__Disease);  post_mp_0__Disease = None\n",
      "    post_mp_2__Compound = getattr(self.post_mp, \"2\").Compound(post_mp_1__Compound);  post_mp_1__Compound = None\n",
      "    post_mp_2__Disease = getattr(self.post_mp, \"2\").Disease(post_mp_1__Disease);  post_mp_1__Disease = None\n",
      "    return {'Compound': post_mp_2__Compound, 'Disease': post_mp_2__Disease}\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "LinkPredictorMLP(\n",
      "  (mlp_layers): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=524, out_features=524, bias=True)\n",
      "    (2): Linear(in_features=524, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Models Loaded to cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (convs): ModuleList(\n",
       "    (0): ModuleDict(\n",
       "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(768, 524, aggr=mean)\n",
       "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(768, 524, aggr=mean)\n",
       "    )\n",
       "    (1-2): 2 x ModuleDict(\n",
       "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(524, 524, aggr=mean)\n",
       "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(524, 524, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (post_mp): ModuleList(\n",
       "    (0): ModuleDict(\n",
       "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
       "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
       "    )\n",
       "    (1): ModuleDict(\n",
       "      (Compound): Dropout(p=0.7, inplace=False)\n",
       "      (Disease): Dropout(p=0.7, inplace=False)\n",
       "    )\n",
       "    (2): ModuleDict(\n",
       "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
       "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs        = 500\n",
    "hidden_dim    = 524      # 256 \n",
    "dropout       = 0.7\n",
    "num_layers    = 3\n",
    "learning_rate = 1e-4\n",
    "node_emb_dim  = 768\n",
    "device        = \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "HomoGNN         = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embedding=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\n",
    "HeteroGNN       = to_hetero(HomoGNN   , data.metadata(), aggr='sum')\n",
    "link_predictor  = LinkPredictorMLP(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device) # the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\n",
    "#optimizer      = torch.optim.AdamW(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate, weight_decay=1e-4)\n",
    "optimizer       = torch.optim.Adam(list(HeteroGNN.parameters()) + list(link_predictor.parameters() ), lr=learning_rate)\n",
    "\n",
    "print(HeteroGNN )\n",
    "print(link_predictor)\n",
    "print(f\"Models Loaded to {device}\")\n",
    "data.to(device)\n",
    "HeteroGNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb   = HeteroGNN(data.x_dict, data.edge_index_dict)\n",
    "edge_index = data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_index \n",
    "pos_pred   = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, link_predictor,data,return_node_emb:bool=False,prediction_entites:tuple=(\"Compound\",\"Disease\")):\n",
    "    ## If model is provided get GNN embeddings ##\n",
    "    if model !=  None:                                        # If model is provided, embedd\n",
    "        node_emb   = model(data.x_dict, data.edge_index_dict) # Embed Bert Embeddigns with graphsage (N, d) \n",
    "    else:                                                     # else \n",
    "        node_emb = x                                          #  use Bert default  Embedddings\n",
    "   \n",
    "    edge_index = data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "    pred       = link_predictor(node_emb[prediction_entites[0]][edge_index[0]], node_emb[prediction_entites[1]][edge_index[1]])   \n",
    "    if model !=  None and return_node_emb == True:\n",
    "        return (pred,node_emb)\n",
    "    else:\n",
    "        return pred \n",
    "\n",
    "\n",
    "def train(model, link_predictor, data, optimizer,triplet:tuple=('Compound', 'Compound_treats_the_disease', 'Disease'),device:str=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    :param model: Torch Graph model used for updating node embeddings based on message passing \n",
    "        (If None, no embbeding is performed) \n",
    "    :param link_predictor: Torch model used for predicting whether edge exists or not\n",
    "    :param emb: (N, d) Initial node embeddings for all N nodes in graph\n",
    "    :param edge_index: (2, E) Edge index for all edges in the graph\n",
    "\n",
    "    :param optimizer: Torch Optimizer to update model parameters\n",
    "    :return: Average supervision loss over all positive (and correspondingly sampled negative) edges\n",
    "    \"\"\"\n",
    "    if model != None: \n",
    "        model.train()\n",
    "    link_predictor.train()\n",
    "    train_losses = []\n",
    "\n",
    "    optimizer.zero_grad()                                  # Reset Gradients\n",
    "    #edge_index     = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "    #x              = x.squeeze(dim=1)                     # Reshape Feature matrix (|N|,D)\n",
    "    #x , edge_index = x.to(device) , edge_index.to(device) # Move data to devices\n",
    "\n",
    "\n",
    "    ### Step 1: Get Embeddings:\n",
    "    # Run message passing on the inital node embeddings to get updated embeddings\n",
    "\n",
    "    ### This model has the option of only running link predictor without graphsage, for that case the node embedding\n",
    "    ### is equal to the original embedding (X)\n",
    "    pred           = forward_pass(model, link_predictor,data,return_node_emb=False)\n",
    "    ground_truth   = data[triplet].edge_label.to(device)\n",
    "    ground_truth[ground_truth  == 2] = 1\n",
    "    #print(ground_truth)\n",
    "    \n",
    "    \n",
    "    loss = F.binary_cross_entropy_with_logits(pred, ground_truth.unsqueeze(1).float())\n",
    "    loss.backward()    # Backpropagate and update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    return sum(train_losses) / len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label = torch.ones(data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_index.shape[1], dtype=torch.long).to(device)\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.5,\n",
    "    neg_sampling_ratio=2,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=(\"Compound\", \"Compound_treats_the_disease\", \"Disease\"),\n",
    "    rev_edge_types=(\"Compound\", \"rev_Compound_treats_the_disease\", \"Disease\"), \n",
    "   \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "\n",
    "#print(f\"Train Data:\\n{train_data}\")\n",
    "#print(f\"Validation Data:\\n{val_data}\")\n",
    "#print(f\"Test Data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58266, 1])\n"
     ]
    }
   ],
   "source": [
    "node_emb   = HeteroGNN(train_data.x_dict, train_data.edge_index_dict)\n",
    "edge_index = train_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "pos_pred   = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )/'\n",
    "\n",
    "print(pos_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 0.80813\n",
      "Epoch 2: loss: 0.80768\n",
      "Epoch 3: loss: 0.80718\n",
      "Epoch 4: loss: 0.8066\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m epochs                          \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,epochs):\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m### TRAIN ####\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mHeteroGNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_predictor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(loss,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, link_predictor, data, optimizer, triplet, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()                                  \u001b[38;5;66;03m# Reset Gradients\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#edge_index     = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#x              = x.squeeze(dim=1)                     # Reshape Feature matrix (|N|,D)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#x , edge_index = x.to(device) , edge_index.to(device) # Move data to devices\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m### This model has the option of only running link predictor without graphsage, for that case the node embedding\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m### is equal to the original embedding (X)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m pred           \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_predictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_node_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m ground_truth   \u001b[38;5;241m=\u001b[39m data[triplet]\u001b[38;5;241m.\u001b[39medge_label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m ground_truth[ground_truth  \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, link_predictor, data, return_node_emb, prediction_entites)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(model, link_predictor,data,return_node_emb:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,prediction_entites:\u001b[38;5;28mtuple\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m## If model is provided get GNN embeddings ##\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m  \u001b[38;5;28;01mNone\u001b[39;00m:                                        \u001b[38;5;66;03m# If model is provided, embedd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m         node_emb   \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Embed Bert Embeddigns with graphsage (N, d) \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:                                                     \u001b[38;5;66;03m# else \u001b[39;00m\n\u001b[1;32m      6\u001b[0m         node_emb \u001b[38;5;241m=\u001b[39m x                                          \u001b[38;5;66;03m#  use Bert default  Embedddings\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.3:21\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m relu_1__Compound \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(convs_1__Compound, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m);  convs_1__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m relu_1__Disease \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(convs_1__Disease, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m);  convs_1__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m dropout_1__Compound \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelu_1__Compound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m;  relu_1__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m dropout_1__Disease \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(relu_1__Disease, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m);  relu_1__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m convs_2__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mCompound__Compound_treats_the_disease__Disease((dropout_1__Compound, dropout_1__Disease), edge_index__Compound__Compound_treats_the_disease__Disease);  edge_index__Compound__Compound_treats_the_disease__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss                      = []\n",
    "train_accuracy                  = []\n",
    "show_metrics_every              = 20\n",
    "best_accuracy                   = 0 \n",
    "best_graphsage_model_path       = \"\"\n",
    "best_link_predictor_model_path  = \"\"\n",
    "epochs                          = 5000\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    \n",
    "    ### TRAIN ####\n",
    "    loss = train(model =  HeteroGNN, link_predictor = link_predictor, data = train_data, optimizer =  optimizer,device=device)\n",
    "    train_loss.append(loss)\n",
    "    print(f\"Epoch {epoch}: loss: {round(loss, 5)}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "with torch.no_grad():\n",
    "    node_emb         = HeteroGNN(val_data.x_dict, val_data.edge_index_dict)\n",
    "    edge_index       = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "    \n",
    "    pos_pred         = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )\n",
    "    ground_truth     = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label\n",
    "    ground_truth[ground_truth  == 2] = 1\n",
    "\n",
    "    acc           = accuracy_score(pos_pred.to(\"cpu\")  > threshold  ,ground_truth.to(\"cpu\") )\n",
    "    print(acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions  = forward_pass(model =  HeteroGNN, link_predictor = link_predictor, data = train_data)\n",
    "ground_truth     = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label\n",
    "ground_truth[ground_truth  == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        ...,\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ground_truth )\n",
    "\n",
    "print(predictions  > 0.5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "simp",
   "language": "python",
   "name": "simp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d42bd2c408a4bd3bdebc2865ea42483": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6e79954f9c514f099b336e3a11ad635e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2e0878218c4b38974a74a673b70751",
      "placeholder": "​",
      "style": "IPY_MODEL_98ccadd9e4a34d8282282a332fad6e0b",
      "value": "Downloading chembl_32_sqlite.tar.gz: 100%"
     }
    },
    "6f2e0878218c4b38974a74a673b70751": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ccadd9e4a34d8282282a332fad6e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a95662c4dc0949f4af40e8331cde378d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eec53708d80f41e8b402060c9a1352b1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f87f682db17a4e6b837b9c14c85ec36f",
      "value": 1
     }
    },
    "b0797e6674144b1b92d2ff70918b917c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b355679609b749d698029d4f39d45503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e79954f9c514f099b336e3a11ad635e",
       "IPY_MODEL_a95662c4dc0949f4af40e8331cde378d",
       "IPY_MODEL_d89d003254ce42f9a44572c7e26940ec"
      ],
      "layout": "IPY_MODEL_2d42bd2c408a4bd3bdebc2865ea42483"
     }
    },
    "d0a9a73a5fe14afb8b15a2addf4f080d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d89d003254ce42f9a44572c7e26940ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0797e6674144b1b92d2ff70918b917c",
      "placeholder": "​",
      "style": "IPY_MODEL_d0a9a73a5fe14afb8b15a2addf4f080d",
      "value": " 4.27G/4.27G [03:38&lt;00:00, 21.7MB/s]"
     }
    },
    "eec53708d80f41e8b402060c9a1352b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "f87f682db17a4e6b837b9c14c85ec36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
