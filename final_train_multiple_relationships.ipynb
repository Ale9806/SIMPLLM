{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnQGl_D4786T"
   },
   "source": [
    "DRKG\n",
    "\n",
    "Adapted from: https://github.com/gnn4dr/DRKG/blob/master/drkg_with_dgl/loading_drkg_in_dgl.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PV4N5XSIKfTa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from   torch.utils.data      import Dataset, DataLoader\n",
    "from   torch_geometric.data  import Data\n",
    "from   torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SIMP_LLM.dataloader_mappings import load_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_as_list(file_path):\n",
    "    data = []\n",
    "    set_ = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[3] == 'Atc' or row[3] == \"Tax\":\n",
    "                continue\n",
    "            else:\n",
    "                data.append((row[1],row[2],row[3]))\n",
    "    return data\n",
    "triplets = load_csv_as_list('triplets.csv')\n",
    "#triplets =  list(set(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2\n"
     ]
    }
   ],
   "source": [
    "triplets =[('Compound', 'Compound_treats_the_disease', 'Disease')]\n",
    "data = load_graph(triplets )\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = torch.load(\"data2/mapping_dict\")\n",
    "#dictionaries[\"Compound\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not work return  true \n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim:int, hidden_dim:int, output_dim:int, layers:int, dropout:float=0.3, return_embedding=True):\n",
    "        \"\"\"\n",
    "            A stack of GraphSAGE Module \n",
    "            input_dim        <int>:   Input dimension\n",
    "            hidden_dim       <int>:   Hidden dimension\n",
    "            output_dim       <int>:   Output dimension\n",
    "            layers           <int>:   Number of layers\n",
    "            dropout          <float>: Dropout rate\n",
    "            return_embedding <bool>:  Whether to return the return_embeddingedding of the input graph\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        graphSage_conv               = pyg.nn.SAGEConv\n",
    "        self.dropout                 = dropout\n",
    "        self.layers                  = layers\n",
    "        self.return_embedding        = return_embedding\n",
    "        #self.training                = train\n",
    "\n",
    "        ### Initalize the layers ###\n",
    "        self.convs                   = nn.ModuleList()                      # ModuleList to hold the layers\n",
    "        for l in range(self.layers):\n",
    "            if l == 0:\n",
    "                ### First layer  maps from input_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                ### All other layers map from hidden_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing processing MLP\n",
    "        self.post_mp = nn.Sequential(\n",
    "                                     nn.Linear(hidden_dim, hidden_dim), \n",
    "                                     nn.Dropout(self.dropout ),\n",
    "                                     nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return final layer of return_embeddingeddings if specified\n",
    "        if self.return_embedding:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    #def loss(self, pred, label):\n",
    "    #    return F.nll_loss(pred, label)\n",
    "    \n",
    "\n",
    "\n",
    "class LinkPredictorMLP(nn.Module):\n",
    "    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int):     Number of input features.\n",
    "            hidden_channels (int): Number of hidden features.\n",
    "            out_channels (int):    Number of output features.\n",
    "            n_layers (int):        Number of MLP layers.\n",
    "            dropout (float):       Dropout probability.\n",
    "            \"\"\"\n",
    "        super(LinkPredictorMLP, self).__init__()\n",
    "        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n",
    "        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n",
    "        self.non_linearity         = F.relu              # non-linearity\n",
    "        \n",
    "        for i in range(n_layers - 1):                                 \n",
    "            if i == 0:\n",
    "                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n",
    "            else:\n",
    "                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n",
    "\n",
    "        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for mlp_layer in self.mlp_layers:\n",
    "            mlp_layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j                                                     # element-wise multiplication\n",
    "        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n",
    "            x = mlp_layer(x)                                              # apply linear transformation\n",
    "            x = self.non_linearity(x)                                     # Apply non linear activation function\n",
    "            x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n",
    "            #x = F.dropout(x, p=self.dropout_probabilty)      # Apply dropout\n",
    "        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n",
    "        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CosineSimilarityModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CosineSimilarityModel, self).__init__()\n",
    "        #self.fc  = nn.Linear(input_dim, 1)\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Normalize the input vectors\n",
    "        x1 = F.normalize(x1, p=2, dim=1)\n",
    "        x2 = F.normalize(x2, p=2, dim=1)\n",
    "        #print(x1.shape)\n",
    "        \n",
    "        # Compute the cosine similarity\n",
    "        similarity = self.cos(x1, x2)\n",
    "       # print(x1.shape)\n",
    "        \n",
    "        # Pass through a linear layer\n",
    "        #output = self.fc(similarity)\n",
    "        \n",
    "        # Apply sigmoid activation to get the final similarity prediction\n",
    "        prediction = torch.sigmoid(similarity)\n",
    "        \n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "### We will use This function to save our best model during trainnig ###\n",
    "def save_torch_model(model,epoch,PATH:str,optimizer):\n",
    "    print(f\"Saving Model in Path {PATH}\")\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer':optimizer,      \n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input1 = torch.randn(100, 128)\n",
    "#input2 = torch.randn(100, 128)\n",
    "#output = link_predictor(input1, input2)  \n",
    "#cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "#output = cos(input1, input2)\n",
    "#output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
       "  \u001b[1mDisease\u001b[0m={ x=[4098, 768] },\n",
       "  \u001b[1m(Compound, Compound_treats_the_disease, Disease)\u001b[0m={ edge_index=[2, 48554] },\n",
       "  \u001b[1m(Disease, rev_Compound_treats_the_disease, Compound)\u001b[0m={ edge_index=[2, 48554] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(768, 524, aggr=mean)\n",
      "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(768, 524, aggr=mean)\n",
      "    )\n",
      "    (1-2): 2 x ModuleDict(\n",
      "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(524, 524, aggr=mean)\n",
      "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(524, 524, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (post_mp): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (Compound): Dropout(p=0.7, inplace=False)\n",
      "      (Disease): Dropout(p=0.7, inplace=False)\n",
      "    )\n",
      "    (2): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__Compound = x_dict.get('Compound', None)\n",
      "    x__Disease = x_dict.get('Disease', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__Compound__Compound_treats_the_disease__Disease = edge_index_dict.get(('Compound', 'Compound_treats_the_disease', 'Disease'), None)\n",
      "    edge_index__Disease__rev_Compound_treats_the_disease__Compound = edge_index_dict.get(('Disease', 'rev_Compound_treats_the_disease', 'Compound'), None);  edge_index_dict = None\n",
      "    convs_0__Disease = getattr(self.convs, \"0\").Compound__Compound_treats_the_disease__Disease((x__Compound, x__Disease), edge_index__Compound__Compound_treats_the_disease__Disease)\n",
      "    convs_0__Compound = getattr(self.convs, \"0\").Disease__rev_Compound_treats_the_disease__Compound((x__Disease, x__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  x__Disease = x__Compound = None\n",
      "    relu__Compound = torch.nn.functional.relu(convs_0__Compound, inplace = False);  convs_0__Compound = None\n",
      "    relu__Disease = torch.nn.functional.relu(convs_0__Disease, inplace = False);  convs_0__Disease = None\n",
      "    dropout__Compound = torch.nn.functional.dropout(relu__Compound, p = 0.7, training = True, inplace = False);  relu__Compound = None\n",
      "    dropout__Disease = torch.nn.functional.dropout(relu__Disease, p = 0.7, training = True, inplace = False);  relu__Disease = None\n",
      "    convs_1__Disease = getattr(self.convs, \"1\").Compound__Compound_treats_the_disease__Disease((dropout__Compound, dropout__Disease), edge_index__Compound__Compound_treats_the_disease__Disease)\n",
      "    convs_1__Compound = getattr(self.convs, \"1\").Disease__rev_Compound_treats_the_disease__Compound((dropout__Disease, dropout__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  dropout__Disease = dropout__Compound = None\n",
      "    relu_1__Compound = torch.nn.functional.relu(convs_1__Compound, inplace = False);  convs_1__Compound = None\n",
      "    relu_1__Disease = torch.nn.functional.relu(convs_1__Disease, inplace = False);  convs_1__Disease = None\n",
      "    dropout_1__Compound = torch.nn.functional.dropout(relu_1__Compound, p = 0.7, training = True, inplace = False);  relu_1__Compound = None\n",
      "    dropout_1__Disease = torch.nn.functional.dropout(relu_1__Disease, p = 0.7, training = True, inplace = False);  relu_1__Disease = None\n",
      "    convs_2__Disease = getattr(self.convs, \"2\").Compound__Compound_treats_the_disease__Disease((dropout_1__Compound, dropout_1__Disease), edge_index__Compound__Compound_treats_the_disease__Disease);  edge_index__Compound__Compound_treats_the_disease__Disease = None\n",
      "    convs_2__Compound = getattr(self.convs, \"2\").Disease__rev_Compound_treats_the_disease__Compound((dropout_1__Disease, dropout_1__Compound), edge_index__Disease__rev_Compound_treats_the_disease__Compound);  dropout_1__Disease = dropout_1__Compound = edge_index__Disease__rev_Compound_treats_the_disease__Compound = None\n",
      "    relu_2__Compound = torch.nn.functional.relu(convs_2__Compound, inplace = False);  convs_2__Compound = None\n",
      "    relu_2__Disease = torch.nn.functional.relu(convs_2__Disease, inplace = False);  convs_2__Disease = None\n",
      "    dropout_2__Compound = torch.nn.functional.dropout(relu_2__Compound, p = 0.7, training = True, inplace = False);  relu_2__Compound = None\n",
      "    dropout_2__Disease = torch.nn.functional.dropout(relu_2__Disease, p = 0.7, training = True, inplace = False);  relu_2__Disease = None\n",
      "    post_mp_0__Compound = getattr(self.post_mp, \"0\").Compound(dropout_2__Compound);  dropout_2__Compound = None\n",
      "    post_mp_0__Disease = getattr(self.post_mp, \"0\").Disease(dropout_2__Disease);  dropout_2__Disease = None\n",
      "    post_mp_1__Compound = getattr(self.post_mp, \"1\").Compound(post_mp_0__Compound);  post_mp_0__Compound = None\n",
      "    post_mp_1__Disease = getattr(self.post_mp, \"1\").Disease(post_mp_0__Disease);  post_mp_0__Disease = None\n",
      "    post_mp_2__Compound = getattr(self.post_mp, \"2\").Compound(post_mp_1__Compound);  post_mp_1__Compound = None\n",
      "    post_mp_2__Disease = getattr(self.post_mp, \"2\").Disease(post_mp_1__Disease);  post_mp_1__Disease = None\n",
      "    return {'Compound': post_mp_2__Compound, 'Disease': post_mp_2__Disease}\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "CosineSimilarityModel(\n",
      "  (cos): CosineSimilarity()\n",
      ")\n",
      "Models Loaded to cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (convs): ModuleList(\n",
       "    (0): ModuleDict(\n",
       "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(768, 524, aggr=mean)\n",
       "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(768, 524, aggr=mean)\n",
       "    )\n",
       "    (1-2): 2 x ModuleDict(\n",
       "      (Compound__Compound_treats_the_disease__Disease): SAGEConv(524, 524, aggr=mean)\n",
       "      (Disease__rev_Compound_treats_the_disease__Compound): SAGEConv(524, 524, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (post_mp): ModuleList(\n",
       "    (0): ModuleDict(\n",
       "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
       "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
       "    )\n",
       "    (1): ModuleDict(\n",
       "      (Compound): Dropout(p=0.7, inplace=False)\n",
       "      (Disease): Dropout(p=0.7, inplace=False)\n",
       "    )\n",
       "    (2): ModuleDict(\n",
       "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
       "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs        = 500\n",
    "hidden_dim    = 524      # 256 \n",
    "dropout       = 0.7\n",
    "num_layers    = 3\n",
    "learning_rate = 1e-4\n",
    "node_emb_dim  = 768\n",
    "device        = \"cuda\"\n",
    "head          = \"COSINE\" # one of \"MLP, COSINE\n",
    "\n",
    "\n",
    "\n",
    "HomoGNN         = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embedding=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\n",
    "HeteroGNN       = to_hetero(HomoGNN   , data.metadata(), aggr='sum')\n",
    "if head == \"MLP\":\n",
    "    link_predictor  = LinkPredictorMLP(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device) # the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\n",
    "if head == \"COSINE\":\n",
    "    link_predictor = CosineSimilarityModel(input_dim=524 ).to(device)\n",
    "\n",
    "#optimizer      = torch.optim.AdamW(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate, weight_decay=1e-4)\n",
    "if head ==  \"MLP\":\n",
    "    optimizer       = torch.optim.Adam(list(HeteroGNN.parameters()) + list(link_predictor.parameters() ), lr=learning_rate)\n",
    "elif head == \"COSINE\":\n",
    "    optimizer       = torch.optim.Adam(list(HeteroGNN.parameters()) , lr=learning_rate)\n",
    "    \n",
    "\n",
    "print(HeteroGNN )\n",
    "print(link_predictor)\n",
    "print(f\"Models Loaded to {device}\")\n",
    "data.to(device)\n",
    "HeteroGNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5123, 0.5097, 0.5047,  ..., 0.4879, 0.4781, 0.5085], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "node_emb   = HeteroGNN(data.x_dict, data.edge_index_dict)\n",
    "edge_index = data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_index \n",
    "pos_pred   = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )\n",
    "print(pos_pred )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48554, 524])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_emb[\"Compound\"][edge_index[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48554, 524])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_emb[\"Disease\"][edge_index[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, link_predictor,data,return_node_emb:bool=False,prediction_entites:tuple=(\"Compound\",\"Disease\")):\n",
    "    ## If model is provided get GNN embeddings ##\n",
    "    if model !=  None:                                        # If model is provided, embedd\n",
    "        node_emb   = model(data.x_dict, data.edge_index_dict) # Embed Bert Embeddigns with graphsage (N, d) \n",
    "    else:                                                     # else \n",
    "        node_emb = x                                          #  use Bert default  Embedddings\n",
    "   \n",
    "    edge_index = data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "    pred       = link_predictor(node_emb[prediction_entites[0]][edge_index[0]], node_emb[prediction_entites[1]][edge_index[1]])   \n",
    "    if model !=  None and return_node_emb == True:\n",
    "        return (pred,node_emb)\n",
    "    else:\n",
    "        return pred \n",
    "\n",
    "\n",
    "def train(model, link_predictor, data, optimizer,triplet:tuple=('Compound', 'Compound_treats_the_disease', 'Disease'),device:str=\"cuda\",head=\"COSINE\"):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    :param model: Torch Graph model used for updating node embeddings based on message passing \n",
    "        (If None, no embbeding is performed) \n",
    "    :param link_predictor: Torch model used for predicting whether edge exists or not\n",
    "    :param emb: (N, d) Initial node embeddings for all N nodes in graph\n",
    "    :param edge_index: (2, E) Edge index for all edges in the graph\n",
    "\n",
    "    :param optimizer: Torch Optimizer to update model parameters\n",
    "    :return: Average supervision loss over all positive (and correspondingly sampled negative) edges\n",
    "    \"\"\"\n",
    "    if model != None: \n",
    "        model.train()\n",
    "    link_predictor.train()\n",
    "    train_losses = []\n",
    "\n",
    "    optimizer.zero_grad()                                  # Reset Gradients\n",
    "    #edge_index     = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "    #x              = x.squeeze(dim=1)                     # Reshape Feature matrix (|N|,D)\n",
    "    #x , edge_index = x.to(device) , edge_index.to(device) # Move data to devices\n",
    "\n",
    "\n",
    "    ### Step 1: Get Embeddings:\n",
    "    # Run message passing on the inital node embeddings to get updated embeddings\n",
    "\n",
    "    ### This model has the option of only running link predictor without graphsage, for that case the node embedding\n",
    "    ### is equal to the original embedding (X)\n",
    "    pred           = forward_pass(model, link_predictor,data,return_node_emb=False)\n",
    "    ground_truth   = data[triplet].edge_label.to(device)\n",
    "    ground_truth[ground_truth  == 2] = 1\n",
    "    #print(ground_truth)\n",
    "    \n",
    "    if head == \"MLP\":\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth.unsqueeze(1).float())\n",
    "    if head == \"COSINE\":\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth.float())\n",
    "    loss.backward()    # Backpropagate and update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    return sum(train_losses) / len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label = torch.ones(data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_index.shape[1], dtype=torch.long).to(device)\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.5,\n",
    "    neg_sampling_ratio=2,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=(\"Compound\", \"Compound_treats_the_disease\", \"Disease\"),\n",
    "    rev_edge_types=(\"Compound\", \"rev_Compound_treats_the_disease\", \"Disease\"), \n",
    "   \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "\n",
    "#print(f\"Train Data:\\n{train_data}\")\n",
    "#print(f\"Validation Data:\\n{val_data}\")\n",
    "#print(f\"Test Data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58266])\n"
     ]
    }
   ],
   "source": [
    "node_emb   = HeteroGNN(train_data.x_dict, train_data.edge_index_dict)\n",
    "edge_index = train_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "pos_pred   = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )/'\n",
    "\n",
    "print(pos_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss: 0.73571\n",
      "Epoch 2: loss: 0.73442\n",
      "Epoch 3: loss: 0.73341\n",
      "Epoch 4: loss: 0.73242\n",
      "Epoch 5: loss: 0.73143\n",
      "Epoch 6: loss: 0.73075\n",
      "Epoch 7: loss: 0.72983\n",
      "Epoch 8: loss: 0.72881\n",
      "Epoch 9: loss: 0.72837\n"
     ]
    }
   ],
   "source": [
    "train_loss                      = []\n",
    "train_accuracy                  = []\n",
    "show_metrics_every              = 20\n",
    "best_accuracy                   = 0 \n",
    "best_graphsage_model_path       = \"\"\n",
    "best_link_predictor_model_path  = \"\"\n",
    "epochs                          = 10\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    \n",
    "    ### TRAIN ####\n",
    "    loss = train(model =  HeteroGNN, link_predictor = link_predictor, data = train_data, optimizer =  optimizer,device=device,head=head)\n",
    "    train_loss.append(loss)\n",
    "    print(f\"Epoch {epoch}: loss: {round(loss, 5)}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def filter_edge_index_by_value(edge_index, value,return_mask=True):\n",
    "    mask = edge_index[0] == value\n",
    "    filtered_edge_index = edge_index[:, mask]\n",
    "    if return_mask:\n",
    "        return filtered_edge_index, mask\n",
    "    else:\n",
    "        return filtered_edge_index\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795056642636457\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "HeteroGNN.eval()\n",
    "link_predictor.eval()\n",
    "with torch.no_grad():\n",
    "    node_emb         = HeteroGNN(val_data.x_dict, val_data.edge_index_dict)\n",
    "    edge_index       = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index\n",
    "    pos_pred         = link_predictor(node_emb[\"Compound\"][edge_index[0]], node_emb[\"Disease\"][edge_index[1]])   # (B, )\n",
    "    ground_truth     = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label\n",
    "    ground_truth[ground_truth  == 2] = 1\n",
    "\n",
    "    acc           = accuracy_score(pos_pred.to(\"cpu\")  > threshold  ,ground_truth.to(\"cpu\") )\n",
    "    print(acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  557,  2668,  5820,  ..., 12251,  2217, 13587],\n",
       "        [ 3916,  2979,  1422,  ...,  1814,   440,  1972]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   5,    5,    5],\n",
      "        [2504, 1704,  594]], device='cuda:0')\n",
      "tensor([[   5],\n",
      "        [2573]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_filtered_edge_index,test_mask= filter_edge_index_by_value( test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index, 5)\n",
    "print(test_filtered_edge_index)\n",
    "val_filtered_edge_index,val_mask= filter_edge_index_by_value( val_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label_index, 5)\n",
    "print(val_filtered_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label[test_mask])\n",
    "print(val_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label[val_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hexafluronium', 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dictionaries[\"Compound\"].items())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Albuminuria', 2573)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dictionaries[\"Disease\"].items())[2573]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48554])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_predictor(node_emb[\"Compound\"][edge_index[0]],node_emb[\"Compound\"][edge_index[1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14565, 524])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_emb[\"Compound\"][edge_index[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14565, 524])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_emb[\"Disease\"][edge_index[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6372, -0.3990,  0.1416,  ...,  0.0512,  0.4418, -0.3357],\n",
       "        [ 0.2890, -0.3826, -0.6336,  ..., -0.4824,  0.2534, -0.2088],\n",
       "        [-2.8462,  3.1066, -0.8212,  ..., -3.2524, -2.9875,  3.4740],\n",
       "        ...,\n",
       "        [-0.3396,  3.0328, -1.0331,  ..., -2.5687, -2.9079,  2.1586],\n",
       "        [-2.8309,  4.0775, -1.6261,  ..., -2.1600, -2.6251,  2.3394],\n",
       "        [-1.4095,  3.8263, -0.7301,  ..., -1.8861, -3.4007,  1.8944]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_emb['Compound'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions  = forward_pass(model =  HeteroGNN, link_predictor = link_predictor, data = train_data)\n",
    "ground_truth     = test_data['Compound', 'Compound_treats_the_disease', 'Disease'].edge_label\n",
    "ground_truth[ground_truth  == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        ...,\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ground_truth )\n",
    "\n",
    "print(predictions  > 0.5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "simp",
   "language": "python",
   "name": "simp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d42bd2c408a4bd3bdebc2865ea42483": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6e79954f9c514f099b336e3a11ad635e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2e0878218c4b38974a74a673b70751",
      "placeholder": "​",
      "style": "IPY_MODEL_98ccadd9e4a34d8282282a332fad6e0b",
      "value": "Downloading chembl_32_sqlite.tar.gz: 100%"
     }
    },
    "6f2e0878218c4b38974a74a673b70751": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ccadd9e4a34d8282282a332fad6e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a95662c4dc0949f4af40e8331cde378d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eec53708d80f41e8b402060c9a1352b1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f87f682db17a4e6b837b9c14c85ec36f",
      "value": 1
     }
    },
    "b0797e6674144b1b92d2ff70918b917c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b355679609b749d698029d4f39d45503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e79954f9c514f099b336e3a11ad635e",
       "IPY_MODEL_a95662c4dc0949f4af40e8331cde378d",
       "IPY_MODEL_d89d003254ce42f9a44572c7e26940ec"
      ],
      "layout": "IPY_MODEL_2d42bd2c408a4bd3bdebc2865ea42483"
     }
    },
    "d0a9a73a5fe14afb8b15a2addf4f080d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d89d003254ce42f9a44572c7e26940ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0797e6674144b1b92d2ff70918b917c",
      "placeholder": "​",
      "style": "IPY_MODEL_d0a9a73a5fe14afb8b15a2addf4f080d",
      "value": " 4.27G/4.27G [03:38&lt;00:00, 21.7MB/s]"
     }
    },
    "eec53708d80f41e8b402060c9a1352b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "f87f682db17a4e6b837b9c14c85ec36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
