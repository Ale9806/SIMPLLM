{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DnQGl_D4786T"
   },
   "source": [
    "AUTHORS: Alejandro\n",
    "\n",
    "https://medium.com/@pytorch_geometric/link-prediction-on-heterogeneous-graphs-with-pyg-6d5c29677c70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PV4N5XSIKfTa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ywHcEVMiAdOv"
   },
   "source": [
    "### Build HeteroData Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from   torch.utils.data      import Dataset, DataLoader\n",
    "from   torch_geometric.data  import Data\n",
    "from   torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import torch \n",
    "import os \n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "DATA_PATH = os.path.join(\"data\",\"graph_obj\")\n",
    "GRAPH     = T.ToUndirected()(torch.load(DATA_PATH, map_location=\"cpu\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 48185])\n",
      "HeteroData(\n",
      "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
      "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
      "  \u001b[1m(Compound, treats, Disease)\u001b[0m={ edge_index=[2, 48185] },\n",
      "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "data['Compound'].x  =  GRAPH[\"Compound\"][\"x\"].float().to(\"cpu\")\n",
    "data['Disease'].x   = GRAPH[\"Disease\"][\"x\"].float().to(\"cpu\")\n",
    "ctd                 = GRAPH[(\"Compound\", \"Compound treats the disease\", \"Disease\")][\"edge_index\"].to_sparse().to(\"cpu\")\n",
    "data['Compound', 'treats', 'Disease'].edge_index = ctd\n",
    "target_label                                     = data['Compound', 'treats', 'Disease'].edge_index\n",
    "#data['Compound', 'treats', 'Disease'].edge_label =  torch.ones(target_label.shape[1],)\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(target_label.shape)\n",
    "\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from   torch.utils.data      import Dataset, DataLoader\n",
    "from   torch_geometric.data  import Data\n",
    "from   torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim:int, hidden_dim:int, output_dim:int, layers:int, dropout:float=0.3, return_embedding=False):\n",
    "        \"\"\"\n",
    "            A stack of GraphSAGE Module \n",
    "            input_dim        <int>:   Input dimension\n",
    "            hidden_dim       <int>:   Hidden dimension\n",
    "            output_dim       <int>:   Output dimension\n",
    "            layers           <int>:   Number of layers\n",
    "            dropout          <float>: Dropout rate\n",
    "            return_embedding <bool>:  Whether to return the return_embeddingedding of the input graph\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        graphSage_conv               = pyg.nn.SAGEConv\n",
    "        self.dropout                 = dropout\n",
    "        self.layers                  = layers\n",
    "        self.return_embedding        = return_embedding\n",
    "\n",
    "        ### Initalize the layers ###\n",
    "        self.convs                   = nn.ModuleList()                      # ModuleList to hold the layers\n",
    "        for l in range(self.layers):\n",
    "            if l == 0:\n",
    "                ### First layer  maps from input_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                ### All other layers map from hidden_dim to hidden_dim ###\n",
    "                self.convs.append(graphSage_conv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing processing MLP\n",
    "        self.post_mp = nn.Sequential(\n",
    "                                     nn.Linear(hidden_dim, hidden_dim), \n",
    "                                     nn.Dropout(self.dropout),\n",
    "                                     nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return final layer of return_embeddingeddings if specified\n",
    "        if self.return_embedding:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "    \n",
    "\n",
    "\n",
    "class LinkPredictorMLP(nn.Module):\n",
    "    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int):     Number of input features.\n",
    "            hidden_channels (int): Number of hidden features.\n",
    "            out_channels (int):    Number of output features.\n",
    "            n_layers (int):        Number of MLP layers.\n",
    "            dropout (float):       Dropout probability.\n",
    "            \"\"\"\n",
    "        super(LinkPredictorMLP, self).__init__()\n",
    "        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n",
    "        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n",
    "        self.non_linearity         = F.relu              # non-linearity\n",
    "        \n",
    "        for i in range(n_layers - 1):                                 \n",
    "            if i == 0:\n",
    "                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n",
    "            else:\n",
    "                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n",
    "\n",
    "        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for mlp_layer in self.mlp_layers:\n",
    "            mlp_layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j                                                     # element-wise multiplication\n",
    "        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n",
    "            x = mlp_layer(x)                                              # apply linear transformation\n",
    "            x = self.non_linearity(x)                                     # Apply non linear activation function\n",
    "            x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n",
    "        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n",
    "        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n",
    "        return x\n",
    "    \n",
    "### We will use This function to save our best model during trainnig ###\n",
    "def save_torch_model(model,epoch,PATH:str,optimizer):\n",
    "    print(f\"Saving Model in Path {PATH}\")\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer':optimizer,      \n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, link_predictor, dataset, optimizer,device:str=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    :param model: Torch Graph model used for updating node embeddings based on message passing \n",
    "        (If None, no embbeding is performed) \n",
    "    :param link_predictor: Torch model used for predicting whether edge exists or not\n",
    "    :param emb: (N, d) Initial node embeddings for all N nodes in graph\n",
    "    :param edge_index: (2, E) Edge index for all edges in the graph\n",
    "\n",
    "    :param optimizer: Torch Optimizer to update model parameters\n",
    "    :return: Average supervision loss over all positive (and correspondingly sampled negative) edges\n",
    "    \"\"\"\n",
    "    if model != None:\n",
    "        model.train()\n",
    "    link_predictor.train()\n",
    "    train_losses = []\n",
    "    for x, edge_index in tqdm(dataset):                       # Get X and Index from Dataste\n",
    "        optimizer.zero_grad()                                 # Reset Gradients\n",
    "        edge_index     = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "        x              = x.squeeze(dim=1)                     # Reshape Feature matrix (|N|,D)\n",
    "        x , edge_index = x.to(device) , edge_index.to(device) # Move data to devices\n",
    "        \n",
    "        \n",
    "        ### Step 1: Get Embeddings:\n",
    "        # Run message passing on the inital node embeddings to get updated embeddings\n",
    "        \n",
    "        ### This model has the option of only running link predictor without graphsage, for that case the node embedding\n",
    "        ### is equal to the original embedding (X)\n",
    "        if model !=  None:\n",
    "            node_emb   = model(data.x_dict, data.edge_index_dict) # Embed Bert Embeddigns with graphsage (N, d) \n",
    "            \n",
    "        else:\n",
    "            node_emb = x                     # Else (None) use Bert Embedddings\n",
    "        # Predict the class probabilities on the batch of positive edges using link_predictor\n",
    "        #print(node_emb[edge_index[0]].shape)\n",
    "        edge_index = data['compounds', 'treats', 'disease'].edge_index   \n",
    "        pred       = link_predictor(node_emb[\"compounds\"][edge_index[0]], node_emb[\"disease\"][edge_index[0]])   # (B, )\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "        # Backpropagate and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    return sum(train_losses) / len(train_losses)\n",
    "\n",
    "\n",
    "def evaluate(model, predictor,dataset,device=\"cpu\",threshold=0.5,ppi_:int=0.9,verbose:bool=False,best_accuracy=0,show_extra_metrics:bool=False):\n",
    "    if model != None:\n",
    "        model.eval()\n",
    "    possitive_acc  = 0 \n",
    "    negative_acc   = 0\n",
    "    batches        = 0\n",
    "    if show_extra_metrics:\n",
    "        yhat_total     = []\n",
    "        y_total        = []\n",
    "        \n",
    "    for x, edge_index in dataset:                              # Get X and Index from Dataste\n",
    "\n",
    "        edge_index      = torch.tensor(edge_index).T           # Reshape edge index     (2,|E|)\n",
    "        number_of_edges =  edge_index.shape[1]                 # Retrive number of edges \n",
    "        permutations    =  torch.randperm(number_of_edges)     # Create Permutations for edge index\n",
    "        edge_index      = edge_index[:,permutations]           # Run permutation\n",
    "        limit           = int(ppi_*number_of_edges)            # get limit  (based on ppis to embed)\n",
    "        ppi_index_embed = edge_index[:,0:limit]                # PPI to embed with GraphSage \n",
    "        ppi_index_infer = edge_index[:,limit:]                 # PPI to make inference\n",
    "        \n",
    "        x                    = x.squeeze(dim=1)                          # Reshape Feature matrix (|N|,D)\n",
    "        x ,ppi_index_embed   = x.to(device) , ppi_index_embed.to(device) # Move data to devices\n",
    "        if model !=  None:\n",
    "            node_emb             = model(x,ppi_index_embed)              # Get all node embeddings\n",
    "        else:\n",
    "            node_emb = x                                                 # Else (None) use Bert Embedddings\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\" {limit} Positive Protein Interactions were used to Embed a graph with {number_of_edges} ppi's\")\n",
    "        \n",
    "        del ppi_index_embed \n",
    "        with torch.no_grad():\n",
    "            ### Positive PPI ###\n",
    "            positive_pairs_embeddings = node_emb[ppi_index_infer[0]].to(device), node_emb[ppi_index_infer[1]].to(device)\n",
    "            predictions               = predictor(positive_pairs_embeddings[0], positive_pairs_embeddings[1]) \n",
    "            y                         = torch.ones_like(input=predictions)\n",
    "            predictions,y             = predictions.cpu(),y.cpu()\n",
    "            possitive_acc            += accuracy_score(predictions > threshold  ,y)\n",
    "            if show_extra_metrics:\n",
    "                yhat_total.extend(predictions.tolist())\n",
    "                y_total.extend(y.tolist())\n",
    "                \n",
    "            else:\n",
    "                del y, predictions , positive_pairs_embeddings,ppi_index_infer\n",
    "\n",
    "            ### Negative PPI ##\n",
    "            edge_index  =  edge_index.to(device)\n",
    "            neg_edge    = negative_sampling(edge_index       = edge_index,        # Possitve PPI's\n",
    "                                         num_nodes        = x.shape[0],           # Total number of nodes in graph\n",
    "                                         num_neg_samples  = edge_index.shape[1],  # Same Number of edges as in positive example\n",
    "                                         method           = 'dense',              # Method for edge generation\n",
    "                                         force_undirected = True)                 # Our graph is undirected\n",
    "\n",
    "            negative_pairs_embeddings = node_emb[neg_edge[0]].to(device), node_emb[neg_edge[1]].to(device)\n",
    "            predictions               = predictor(negative_pairs_embeddings[0], negative_pairs_embeddings[1])   \n",
    "            y                         = torch.zeros_like(input=predictions)\n",
    "            predictions,y             = predictions.cpu(),y.cpu()\n",
    "            negative_acc             += accuracy_score(predictions > threshold,y)\n",
    "            if show_extra_metrics:\n",
    "                yhat_total.extend(predictions.tolist())\n",
    "                y_total.extend(y.tolist())\n",
    "                \n",
    "            else:\n",
    "                del y,  predictions  ,negative_pairs_embeddings \n",
    "            batches +=1\n",
    "\n",
    "    negative_acc  = negative_acc/batches\n",
    "    possitive_acc = possitive_acc/batches\n",
    "    total_acc     = 0.5*possitive_acc  + 0.5*negative_acc\n",
    "    if show_extra_metrics == False:\n",
    "        print(f\"Sensitivity (poss_acc):{possitive_acc:.4f} Specificity (negative_acc):{negative_acc:.4f} accuracy:{total_acc:.4f}\")\n",
    "    \n",
    "    elif show_extra_metrics == True:\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2,figsize=(10,2))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve( y_total, yhat_total)\n",
    "        \n",
    "        sens      =  tpr\n",
    "        spec      =  1 - fpr\n",
    "        j         = sens + spec -1\n",
    "        opt_index = np.where(j == np.max(j))[0][0]\n",
    "        op_point  = thresholds[opt_index]\n",
    "        \n",
    "        print(f\"Youdens  index: {op_point:.4f} Sensitivity: {round(sens[opt_index],4)} Specificity: {round(spec[opt_index],4)}\")\n",
    "       \n",
    "        ax[0].set_title(\"ROC Curve\")\n",
    "        ax[1].set_title(\"Confussion Matrix\")\n",
    "        if model == None:\n",
    "            ax[0].plot(fpr,tpr,label=\"MLP\") \n",
    "        else:\n",
    "            ax[0].plot(fpr,tpr,label=\"GraphSage+MLP\") \n",
    "        ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "        ax[0].set_ylabel('True Positive Rate')\n",
    "        ax[0].set_xlabel('False Positive Rate')\n",
    "        ax[0].legend()\n",
    "       \n",
    "    \n",
    "        cfm = metrics.confusion_matrix(y_total, np.array(yhat_total)> op_point)\n",
    "        \n",
    "        cmn = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis] # Normalise\n",
    "        disp = ConfusionMatrixDisplay(cmn)\n",
    "        disp.plot(ax=ax[1])\n",
    "        \n",
    "        plt.show()\n",
    "     \n",
    "    return total_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HeteroData.metadata of HeteroData(\n",
       "  \u001b[1mCompound\u001b[0m={ x=[15182, 768] },\n",
       "  \u001b[1mDisease\u001b[0m={ x=[3750, 768] },\n",
       "  \u001b[1m(Compound, treats, Disease)\u001b[0m={ edge_index=[2, 48185] },\n",
       "  \u001b[1m(Disease, rev_treats, Compound)\u001b[0m={ edge_index=[2, 48185] }\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound__treats__Disease): SAGEConv(768, 524, aggr=mean)\n",
      "      (Disease__rev_treats__Compound): SAGEConv(768, 524, aggr=mean)\n",
      "    )\n",
      "    (1-2): 2 x ModuleDict(\n",
      "      (Compound__treats__Disease): SAGEConv(524, 524, aggr=mean)\n",
      "      (Disease__rev_treats__Compound): SAGEConv(524, 524, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (post_mp): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (Compound): Dropout(p=0.7, inplace=False)\n",
      "      (Disease): Dropout(p=0.7, inplace=False)\n",
      "    )\n",
      "    (2): ModuleDict(\n",
      "      (Compound): Linear(in_features=524, out_features=524, bias=True)\n",
      "      (Disease): Linear(in_features=524, out_features=524, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, edge_index):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__Compound = x_dict.get('Compound', None)\n",
      "    x__Disease = x_dict.get('Disease', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__Compound__treats__Disease = edge_index_dict.get(('Compound', 'treats', 'Disease'), None)\n",
      "    edge_index__Disease__rev_treats__Compound = edge_index_dict.get(('Disease', 'rev_treats', 'Compound'), None);  edge_index_dict = None\n",
      "    convs_0__Disease = getattr(self.convs, \"0\").Compound__treats__Disease((x__Compound, x__Disease), edge_index__Compound__treats__Disease)\n",
      "    convs_0__Compound = getattr(self.convs, \"0\").Disease__rev_treats__Compound((x__Disease, x__Compound), edge_index__Disease__rev_treats__Compound);  x__Disease = x__Compound = None\n",
      "    relu__Compound = torch.nn.functional.relu(convs_0__Compound, inplace = False);  convs_0__Compound = None\n",
      "    relu__Disease = torch.nn.functional.relu(convs_0__Disease, inplace = False);  convs_0__Disease = None\n",
      "    dropout__Compound = torch.nn.functional.dropout(relu__Compound, p = 0.7, training = True, inplace = False);  relu__Compound = None\n",
      "    dropout__Disease = torch.nn.functional.dropout(relu__Disease, p = 0.7, training = True, inplace = False);  relu__Disease = None\n",
      "    convs_1__Disease = getattr(self.convs, \"1\").Compound__treats__Disease((dropout__Compound, dropout__Disease), edge_index__Compound__treats__Disease)\n",
      "    convs_1__Compound = getattr(self.convs, \"1\").Disease__rev_treats__Compound((dropout__Disease, dropout__Compound), edge_index__Disease__rev_treats__Compound);  dropout__Disease = dropout__Compound = None\n",
      "    relu_1__Compound = torch.nn.functional.relu(convs_1__Compound, inplace = False);  convs_1__Compound = None\n",
      "    relu_1__Disease = torch.nn.functional.relu(convs_1__Disease, inplace = False);  convs_1__Disease = None\n",
      "    dropout_1__Compound = torch.nn.functional.dropout(relu_1__Compound, p = 0.7, training = True, inplace = False);  relu_1__Compound = None\n",
      "    dropout_1__Disease = torch.nn.functional.dropout(relu_1__Disease, p = 0.7, training = True, inplace = False);  relu_1__Disease = None\n",
      "    convs_2__Disease = getattr(self.convs, \"2\").Compound__treats__Disease((dropout_1__Compound, dropout_1__Disease), edge_index__Compound__treats__Disease);  edge_index__Compound__treats__Disease = None\n",
      "    convs_2__Compound = getattr(self.convs, \"2\").Disease__rev_treats__Compound((dropout_1__Disease, dropout_1__Compound), edge_index__Disease__rev_treats__Compound);  dropout_1__Disease = dropout_1__Compound = edge_index__Disease__rev_treats__Compound = None\n",
      "    relu_2__Compound = torch.nn.functional.relu(convs_2__Compound, inplace = False);  convs_2__Compound = None\n",
      "    relu_2__Disease = torch.nn.functional.relu(convs_2__Disease, inplace = False);  convs_2__Disease = None\n",
      "    dropout_2__Compound = torch.nn.functional.dropout(relu_2__Compound, p = 0.7, training = True, inplace = False);  relu_2__Compound = None\n",
      "    dropout_2__Disease = torch.nn.functional.dropout(relu_2__Disease, p = 0.7, training = True, inplace = False);  relu_2__Disease = None\n",
      "    post_mp_0__Compound = getattr(self.post_mp, \"0\").Compound(dropout_2__Compound);  dropout_2__Compound = None\n",
      "    post_mp_0__Disease = getattr(self.post_mp, \"0\").Disease(dropout_2__Disease);  dropout_2__Disease = None\n",
      "    post_mp_1__Compound = getattr(self.post_mp, \"1\").Compound(post_mp_0__Compound);  post_mp_0__Compound = None\n",
      "    post_mp_1__Disease = getattr(self.post_mp, \"1\").Disease(post_mp_0__Disease);  post_mp_0__Disease = None\n",
      "    post_mp_2__Compound = getattr(self.post_mp, \"2\").Compound(post_mp_1__Compound);  post_mp_1__Compound = None\n",
      "    post_mp_2__Disease = getattr(self.post_mp, \"2\").Disease(post_mp_1__Disease);  post_mp_1__Disease = None\n",
      "    return {'Compound': post_mp_2__Compound, 'Disease': post_mp_2__Disease}\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "LinkPredictorMLP(\n",
      "  (mlp_layers): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=524, out_features=524, bias=True)\n",
      "    (2): Linear(in_features=524, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Models Loaded to cpu\n"
     ]
    }
   ],
   "source": [
    "epochs        = 500\n",
    "hidden_dim    = 524      # 256 \n",
    "dropout       = 0.7\n",
    "num_layers    = 3\n",
    "learning_rate = 1e-4\n",
    "node_emb_dim  = 768\n",
    "device        = \"cpu\"\n",
    "\n",
    "HomoGNN         = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embedding=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\n",
    "HeteroGNN       = to_hetero(HomoGNN   , data.metadata(), aggr='sum')\n",
    "link_predictor  = LinkPredictorMLP(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device) # the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\n",
    "#optimizer      = torch.optim.AdamW(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate, weight_decay=1e-4)\n",
    "optimizer       = torch.optim.Adam(list(HeteroGNN.parameters()) + list(link_predictor.parameters() ), lr=learning_rate)\n",
    "\n",
    "print(HeteroGNN )\n",
    "print(link_predictor)\n",
    "print(f\"Models Loaded to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:65: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
      "/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:69: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  src = src.to_sparse_csr()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_emb   \u001b[38;5;241m=\u001b[39m \u001b[43mHeteroGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompounds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisease\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39medge_index \n\u001b[1;32m      3\u001b[0m pos_pred    \u001b[38;5;241m=\u001b[39m link_predictor(node_emb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompounds\u001b[39m\u001b[38;5;124m\"\u001b[39m][edge_index[\u001b[38;5;241m0\u001b[39m]], node_emb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisease\u001b[39m\u001b[38;5;124m\"\u001b[39m][edge_index[\u001b[38;5;241m0\u001b[39m]])   \u001b[38;5;66;03m# (B, )\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:281\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.1:11\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m edge_index__Compound__treats__Disease \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m edge_index__Disease__rev_treats__Compound \u001b[38;5;241m=\u001b[39m edge_index_dict\u001b[38;5;241m.\u001b[39mget((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisease\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrev_treats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompound\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m);  edge_index_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m convs_0__Disease \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompound__treats__Disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__Compound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx__Disease\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index__Compound__treats__Disease\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mDisease__rev_treats__Compound((x__Disease, x__Compound), edge_index__Disease__rev_treats__Compound);  x__Disease \u001b[38;5;241m=\u001b[39m x__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m relu__Compound \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(convs_0__Compound, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m);  convs_0__Compound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:435\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m         edge_index, msg_aggr_kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 435\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_aggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    437\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:150\u001b[0m, in \u001b[0;36mSAGEConv.message_and_aggregate\u001b[0;34m(self, adj_t, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adj_t, SparseTensor):\n\u001b[1;32m    149\u001b[0m     adj_t \u001b[38;5;241m=\u001b[39m adj_t\u001b[38;5;241m.\u001b[39mset_value(\u001b[38;5;28;01mNone\u001b[39;00m, layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/simp/lib/python3.11/site-packages/torch_geometric/utils/spmm.py:84\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(src, other, reduce)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Use the default code path with custom reduction (works on CPU):\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csr \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m src\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Simulate `mean` reduction by dividing by degree:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'other' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for sparse_mm_reduce)"
     ]
    }
   ],
   "source": [
    "node_emb   = HeteroGNN(data.x_dict, data.edge_index_dict)\n",
    "edge_index = data['compounds', 'treats', 'disease'].edge_index \n",
    "pos_pred    = link_predictor(node_emb[\"compounds\"][edge_index[0]], node_emb[\"disease\"][edge_index[0]])   # (B, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5184],\n",
       "        [0.4856],\n",
       "        [0.4953],\n",
       "        [0.5092],\n",
       "        [0.4947],\n",
       "        [0.5142],\n",
       "        [0.5107],\n",
       "        [0.5027],\n",
       "        [0.5004],\n",
       "        [0.4941],\n",
       "        [0.4897],\n",
       "        [0.4992],\n",
       "        [0.4904],\n",
       "        [0.5110],\n",
       "        [0.4954],\n",
       "        [0.5033],\n",
       "        [0.5056],\n",
       "        [0.4836],\n",
       "        [0.5020],\n",
       "        [0.5049],\n",
       "        [0.4978],\n",
       "        [0.5036],\n",
       "        [0.4993],\n",
       "        [0.5033],\n",
       "        [0.5132],\n",
       "        [0.5004],\n",
       "        [0.5130],\n",
       "        [0.4967],\n",
       "        [0.5031],\n",
       "        [0.5005],\n",
       "        [0.5025],\n",
       "        [0.4947],\n",
       "        [0.5097],\n",
       "        [0.5148],\n",
       "        [0.5067],\n",
       "        [0.4963],\n",
       "        [0.4975],\n",
       "        [0.5010],\n",
       "        [0.4936],\n",
       "        [0.5053],\n",
       "        [0.5058],\n",
       "        [0.5101],\n",
       "        [0.4967],\n",
       "        [0.4891],\n",
       "        [0.4929],\n",
       "        [0.4987],\n",
       "        [0.4818],\n",
       "        [0.4959],\n",
       "        [0.4999],\n",
       "        [0.4986],\n",
       "        [0.4968],\n",
       "        [0.5041],\n",
       "        [0.4915],\n",
       "        [0.4974],\n",
       "        [0.4964],\n",
       "        [0.5021],\n",
       "        [0.5118],\n",
       "        [0.5113],\n",
       "        [0.4915],\n",
       "        [0.5081],\n",
       "        [0.5004],\n",
       "        [0.5035],\n",
       "        [0.4923],\n",
       "        [0.4987],\n",
       "        [0.4967],\n",
       "        [0.4988],\n",
       "        [0.5086],\n",
       "        [0.4955],\n",
       "        [0.4791],\n",
       "        [0.4877],\n",
       "        [0.4854],\n",
       "        [0.4954],\n",
       "        [0.5090],\n",
       "        [0.4968],\n",
       "        [0.4921],\n",
       "        [0.5114],\n",
       "        [0.4900],\n",
       "        [0.4920],\n",
       "        [0.4999],\n",
       "        [0.5019],\n",
       "        [0.4893],\n",
       "        [0.4978],\n",
       "        [0.5014],\n",
       "        [0.4973],\n",
       "        [0.4999],\n",
       "        [0.5121],\n",
       "        [0.5043],\n",
       "        [0.4800],\n",
       "        [0.4869],\n",
       "        [0.4989],\n",
       "        [0.4921],\n",
       "        [0.5064],\n",
       "        [0.5001],\n",
       "        [0.4987],\n",
       "        [0.4979],\n",
       "        [0.5023],\n",
       "        [0.5025],\n",
       "        [0.5099],\n",
       "        [0.4969],\n",
       "        [0.4856],\n",
       "        [0.4970],\n",
       "        [0.5026],\n",
       "        [0.5021],\n",
       "        [0.5067],\n",
       "        [0.4975],\n",
       "        [0.4952],\n",
       "        [0.5152],\n",
       "        [0.5030],\n",
       "        [0.5033],\n",
       "        [0.4942],\n",
       "        [0.5116],\n",
       "        [0.4851],\n",
       "        [0.4931],\n",
       "        [0.5042],\n",
       "        [0.5083],\n",
       "        [0.5111],\n",
       "        [0.5002],\n",
       "        [0.5082],\n",
       "        [0.4865],\n",
       "        [0.4931],\n",
       "        [0.4949],\n",
       "        [0.4916],\n",
       "        [0.4928],\n",
       "        [0.5033],\n",
       "        [0.4901],\n",
       "        [0.5041],\n",
       "        [0.4987],\n",
       "        [0.5078],\n",
       "        [0.5017],\n",
       "        [0.4921],\n",
       "        [0.4891],\n",
       "        [0.4810],\n",
       "        [0.5006],\n",
       "        [0.4910],\n",
       "        [0.4918],\n",
       "        [0.4944],\n",
       "        [0.4980],\n",
       "        [0.5059],\n",
       "        [0.4871],\n",
       "        [0.4970],\n",
       "        [0.4895],\n",
       "        [0.5062],\n",
       "        [0.4913],\n",
       "        [0.4866],\n",
       "        [0.4868],\n",
       "        [0.4990],\n",
       "        [0.4972],\n",
       "        [0.4931],\n",
       "        [0.5085],\n",
       "        [0.5013],\n",
       "        [0.4916],\n",
       "        [0.5039],\n",
       "        [0.4839],\n",
       "        [0.4899],\n",
       "        [0.4924],\n",
       "        [0.4967],\n",
       "        [0.5139],\n",
       "        [0.5058],\n",
       "        [0.4983],\n",
       "        [0.5031],\n",
       "        [0.4950],\n",
       "        [0.4919],\n",
       "        [0.4949],\n",
       "        [0.5093],\n",
       "        [0.5086],\n",
       "        [0.5064],\n",
       "        [0.5044],\n",
       "        [0.5098],\n",
       "        [0.4884],\n",
       "        [0.4781],\n",
       "        [0.4998],\n",
       "        [0.5017],\n",
       "        [0.5010],\n",
       "        [0.4862],\n",
       "        [0.5029],\n",
       "        [0.4986],\n",
       "        [0.4937],\n",
       "        [0.5064],\n",
       "        [0.4986],\n",
       "        [0.4816],\n",
       "        [0.5005],\n",
       "        [0.4923],\n",
       "        [0.4863],\n",
       "        [0.5176],\n",
       "        [0.5043],\n",
       "        [0.5030],\n",
       "        [0.4836],\n",
       "        [0.4928],\n",
       "        [0.4917],\n",
       "        [0.4973],\n",
       "        [0.5048],\n",
       "        [0.5012],\n",
       "        [0.4930],\n",
       "        [0.4854],\n",
       "        [0.4946],\n",
       "        [0.4875],\n",
       "        [0.5013],\n",
       "        [0.4980],\n",
       "        [0.4913],\n",
       "        [0.5075],\n",
       "        [0.5031],\n",
       "        [0.4922],\n",
       "        [0.4974],\n",
       "        [0.4977],\n",
       "        [0.5021],\n",
       "        [0.4853],\n",
       "        [0.4947],\n",
       "        [0.5035],\n",
       "        [0.5011],\n",
       "        [0.4909],\n",
       "        [0.5036],\n",
       "        [0.4863],\n",
       "        [0.4941],\n",
       "        [0.5131],\n",
       "        [0.5059],\n",
       "        [0.5072],\n",
       "        [0.4864],\n",
       "        [0.5069],\n",
       "        [0.4849],\n",
       "        [0.4859],\n",
       "        [0.4991],\n",
       "        [0.5072],\n",
       "        [0.5022],\n",
       "        [0.4926],\n",
       "        [0.4949],\n",
       "        [0.4935],\n",
       "        [0.5036],\n",
       "        [0.5090],\n",
       "        [0.5004],\n",
       "        [0.4931],\n",
       "        [0.5032],\n",
       "        [0.5103],\n",
       "        [0.4946],\n",
       "        [0.4977],\n",
       "        [0.5020],\n",
       "        [0.4943],\n",
       "        [0.5049],\n",
       "        [0.4997],\n",
       "        [0.4950],\n",
       "        [0.5065],\n",
       "        [0.4988],\n",
       "        [0.4996],\n",
       "        [0.4877],\n",
       "        [0.4898],\n",
       "        [0.4998],\n",
       "        [0.5018],\n",
       "        [0.4910],\n",
       "        [0.4915],\n",
       "        [0.4812],\n",
       "        [0.5086],\n",
       "        [0.4928],\n",
       "        [0.4982],\n",
       "        [0.5007],\n",
       "        [0.4812],\n",
       "        [0.4865],\n",
       "        [0.5098],\n",
       "        [0.4886],\n",
       "        [0.5010],\n",
       "        [0.4985],\n",
       "        [0.5051],\n",
       "        [0.5088],\n",
       "        [0.5031],\n",
       "        [0.5034],\n",
       "        [0.4812],\n",
       "        [0.4953],\n",
       "        [0.5000],\n",
       "        [0.4974],\n",
       "        [0.4933],\n",
       "        [0.4902],\n",
       "        [0.4979],\n",
       "        [0.5121],\n",
       "        [0.4778],\n",
       "        [0.5158],\n",
       "        [0.5030],\n",
       "        [0.4977],\n",
       "        [0.4799],\n",
       "        [0.4957],\n",
       "        [0.4828],\n",
       "        [0.4968],\n",
       "        [0.4899],\n",
       "        [0.5051],\n",
       "        [0.4926],\n",
       "        [0.4915],\n",
       "        [0.4910],\n",
       "        [0.5097],\n",
       "        [0.5005],\n",
       "        [0.5041],\n",
       "        [0.4989],\n",
       "        [0.4832],\n",
       "        [0.5171],\n",
       "        [0.4992],\n",
       "        [0.4883],\n",
       "        [0.5068],\n",
       "        [0.4914],\n",
       "        [0.4985],\n",
       "        [0.5142],\n",
       "        [0.5086],\n",
       "        [0.4979],\n",
       "        [0.5003],\n",
       "        [0.5042],\n",
       "        [0.5085],\n",
       "        [0.5071],\n",
       "        [0.4928],\n",
       "        [0.4903],\n",
       "        [0.5015],\n",
       "        [0.4880],\n",
       "        [0.4891],\n",
       "        [0.5002],\n",
       "        [0.4864],\n",
       "        [0.4881],\n",
       "        [0.4849],\n",
       "        [0.4902],\n",
       "        [0.5019],\n",
       "        [0.5009],\n",
       "        [0.4994],\n",
       "        [0.4992],\n",
       "        [0.5029],\n",
       "        [0.5011],\n",
       "        [0.5117],\n",
       "        [0.4899],\n",
       "        [0.5029],\n",
       "        [0.4950],\n",
       "        [0.4862],\n",
       "        [0.5048],\n",
       "        [0.4879],\n",
       "        [0.4888],\n",
       "        [0.4996],\n",
       "        [0.4904],\n",
       "        [0.4983],\n",
       "        [0.5072],\n",
       "        [0.4950],\n",
       "        [0.4969],\n",
       "        [0.4851],\n",
       "        [0.5032],\n",
       "        [0.5048],\n",
       "        [0.5036],\n",
       "        [0.5047],\n",
       "        [0.4900],\n",
       "        [0.4965],\n",
       "        [0.5046],\n",
       "        [0.5029],\n",
       "        [0.4808],\n",
       "        [0.4993],\n",
       "        [0.4986],\n",
       "        [0.4953],\n",
       "        [0.5133],\n",
       "        [0.4964],\n",
       "        [0.4972],\n",
       "        [0.5042],\n",
       "        [0.5002],\n",
       "        [0.5047],\n",
       "        [0.5081],\n",
       "        [0.5069],\n",
       "        [0.4962],\n",
       "        [0.5073],\n",
       "        [0.4961],\n",
       "        [0.4955],\n",
       "        [0.5106],\n",
       "        [0.5042],\n",
       "        [0.4900],\n",
       "        [0.5012],\n",
       "        [0.4879],\n",
       "        [0.4953],\n",
       "        [0.4969],\n",
       "        [0.4911],\n",
       "        [0.5119],\n",
       "        [0.4884],\n",
       "        [0.4974],\n",
       "        [0.4992],\n",
       "        [0.4955],\n",
       "        [0.4904],\n",
       "        [0.4894],\n",
       "        [0.4868],\n",
       "        [0.4858],\n",
       "        [0.4933],\n",
       "        [0.5022],\n",
       "        [0.5076],\n",
       "        [0.5105],\n",
       "        [0.5054],\n",
       "        [0.5023],\n",
       "        [0.5063],\n",
       "        [0.5082],\n",
       "        [0.5049],\n",
       "        [0.4982],\n",
       "        [0.4975],\n",
       "        [0.4983],\n",
       "        [0.5027],\n",
       "        [0.4964],\n",
       "        [0.4818],\n",
       "        [0.5086],\n",
       "        [0.4936],\n",
       "        [0.5067],\n",
       "        [0.4976],\n",
       "        [0.5100],\n",
       "        [0.5031],\n",
       "        [0.4792],\n",
       "        [0.5108],\n",
       "        [0.5200],\n",
       "        [0.4962],\n",
       "        [0.4992],\n",
       "        [0.4904],\n",
       "        [0.4853],\n",
       "        [0.4996],\n",
       "        [0.4911],\n",
       "        [0.4962],\n",
       "        [0.4835],\n",
       "        [0.4986],\n",
       "        [0.5016],\n",
       "        [0.4972],\n",
       "        [0.4965],\n",
       "        [0.5057],\n",
       "        [0.4907],\n",
       "        [0.5066],\n",
       "        [0.4959],\n",
       "        [0.5038],\n",
       "        [0.5066],\n",
       "        [0.5016],\n",
       "        [0.4996],\n",
       "        [0.5000],\n",
       "        [0.5094],\n",
       "        [0.4960],\n",
       "        [0.5077],\n",
       "        [0.4988],\n",
       "        [0.5051],\n",
       "        [0.5098],\n",
       "        [0.4988],\n",
       "        [0.5001],\n",
       "        [0.4994],\n",
       "        [0.5001],\n",
       "        [0.5112],\n",
       "        [0.5058],\n",
       "        [0.5012],\n",
       "        [0.4934],\n",
       "        [0.5063],\n",
       "        [0.5115],\n",
       "        [0.4984],\n",
       "        [0.5040],\n",
       "        [0.4969],\n",
       "        [0.5009],\n",
       "        [0.4942],\n",
       "        [0.4879],\n",
       "        [0.5092],\n",
       "        [0.5052],\n",
       "        [0.4968],\n",
       "        [0.4993],\n",
       "        [0.4923],\n",
       "        [0.4970],\n",
       "        [0.5085],\n",
       "        [0.5002],\n",
       "        [0.5000],\n",
       "        [0.4900],\n",
       "        [0.4947],\n",
       "        [0.4883],\n",
       "        [0.4911],\n",
       "        [0.4981],\n",
       "        [0.5096],\n",
       "        [0.4981],\n",
       "        [0.4981],\n",
       "        [0.5037],\n",
       "        [0.4939],\n",
       "        [0.4860],\n",
       "        [0.4809],\n",
       "        [0.5060],\n",
       "        [0.4844],\n",
       "        [0.5291],\n",
       "        [0.5014],\n",
       "        [0.4659],\n",
       "        [0.4827],\n",
       "        [0.4990],\n",
       "        [0.5099],\n",
       "        [0.5106],\n",
       "        [0.5000],\n",
       "        [0.5071],\n",
       "        [0.5135],\n",
       "        [0.4819],\n",
       "        [0.4745],\n",
       "        [0.5021],\n",
       "        [0.5007],\n",
       "        [0.5006],\n",
       "        [0.5092],\n",
       "        [0.4935],\n",
       "        [0.5096],\n",
       "        [0.5023],\n",
       "        [0.5038],\n",
       "        [0.5108],\n",
       "        [0.4860],\n",
       "        [0.5018],\n",
       "        [0.5107],\n",
       "        [0.4980],\n",
       "        [0.5026],\n",
       "        [0.4996],\n",
       "        [0.5098],\n",
       "        [0.5047],\n",
       "        [0.4980],\n",
       "        [0.5061],\n",
       "        [0.5004],\n",
       "        [0.5043],\n",
       "        [0.4962],\n",
       "        [0.4831],\n",
       "        [0.5018]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss                      = []\n",
    "train_accuracy                  = []\n",
    "show_metrics_every              = 20\n",
    "best_accuracy                   = 0 \n",
    "best_graphsage_model_path       = \"\"\n",
    "best_link_predictor_model_path  = \"\"\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    \n",
    "    ### TRAIN ####\n",
    "    loss = train(model, link_predictor,train_dataset, optimizer,device) # Get Loss\n",
    "    train_loss.append(loss)\n",
    "    print(f\"Epoch {epoch}: loss: {round(loss, 5)}\")\n",
    "    \n",
    "    ### EVALUATE ###\n",
    "    if (epoch % 20 == 0) or (epoch ==1):\n",
    "        accuracy = evaluate(model, link_predictor ,test_dataset,device=device,best_accuracy=best_accuracy,show_extra_metrics=True)\n",
    "        \n",
    "    else:\n",
    "        accuracy = evaluate(model, link_predictor ,test_dataset,device=device,best_accuracy=best_accuracy)\n",
    "    \n",
    "    train_accuracy.append(accuracy)\n",
    "    ### SAVE ###\n",
    "    if best_accuracy < accuracy:\n",
    "        if os.path.exists(best_graphsage_model_path):\n",
    "            \n",
    "            os.remove(best_graphsage_model_path)\n",
    "            \n",
    "        if os.path.exists(best_link_predictor_model_path):\n",
    "            os.remove(best_link_predictor_model_path)\n",
    "        print(f\"Replacing models: {best_graphsage_model_path }  {best_link_predictor_model_path}\")\n",
    "            \n",
    "        best_accuracy  = accuracy\n",
    "        best_graphsage_model_path      = f\"GraphSage_epoch_{epoch}.pt\"\n",
    "        best_link_predictor_model_path =  f\"link_predictor_epoch_{epoch}.pt\"\n",
    "        print(f\"with: Best models at {best_graphsage_model_path }  {best_link_predictor_model_path}\")\n",
    "        save_torch_model(model,         epoch=epoch,PATH=best_graphsage_model_path ,     optimizer=optimizer)\n",
    "        save_torch_model(link_predictor,epoch=epoch,PATH=best_link_predictor_model_path, optimizer=optimizer)\n",
    "\n",
    "        \n",
    "#### Load Best Models ####\n",
    "\n",
    "print(f\"Loading best models:  {best_graphsage_model_path }  {best_link_predictor_model_path}\")\n",
    "checkpoint = torch.load(best_graphsage_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "checkpoint = torch.load(best_link_predictor_model_path)\n",
    "link_predictor.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "del checkpoint\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d42bd2c408a4bd3bdebc2865ea42483": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6e79954f9c514f099b336e3a11ad635e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2e0878218c4b38974a74a673b70751",
      "placeholder": "",
      "style": "IPY_MODEL_98ccadd9e4a34d8282282a332fad6e0b",
      "value": "Downloading chembl_32_sqlite.tar.gz: 100%"
     }
    },
    "6f2e0878218c4b38974a74a673b70751": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ccadd9e4a34d8282282a332fad6e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a95662c4dc0949f4af40e8331cde378d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eec53708d80f41e8b402060c9a1352b1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f87f682db17a4e6b837b9c14c85ec36f",
      "value": 1
     }
    },
    "b0797e6674144b1b92d2ff70918b917c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b355679609b749d698029d4f39d45503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e79954f9c514f099b336e3a11ad635e",
       "IPY_MODEL_a95662c4dc0949f4af40e8331cde378d",
       "IPY_MODEL_d89d003254ce42f9a44572c7e26940ec"
      ],
      "layout": "IPY_MODEL_2d42bd2c408a4bd3bdebc2865ea42483"
     }
    },
    "d0a9a73a5fe14afb8b15a2addf4f080d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d89d003254ce42f9a44572c7e26940ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0797e6674144b1b92d2ff70918b917c",
      "placeholder": "",
      "style": "IPY_MODEL_d0a9a73a5fe14afb8b15a2addf4f080d",
      "value": " 4.27G/4.27G [03:38&lt;00:00, 21.7MB/s]"
     }
    },
    "eec53708d80f41e8b402060c9a1352b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "f87f682db17a4e6b837b9c14c85ec36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
